{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4 Data Cleaning\n",
    "\n",
    "#### Navya Mangipudi, Big Data & Analytics, 10-29-19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this lab, I will be exploring datasets and seeing which ones I want to clean based on information I find through .info() and .columns. After that, I will be cleaning columns of the dataset and implementing methods of cleaning learned in class and throygh other resources to make the sets better for potential data modeling/analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Exploration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1275,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here, I am importing useful packages that I may potentially use later in the lab. \n",
    "import math as m\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1276,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, I am opening all of the potential files for data cleaning available. This includes the files with data \n",
    "#for sales, candy responses and attendance. \n",
    "\n",
    "dfs = pd.read_csv(\"sales.csv\", encoding = 'latin1')\n",
    "\n",
    "dfc = pd.read_csv(\"Candy_Responses.csv\", encoding = 'latin1')\n",
    "\n",
    "dfa = pd.read_csv(\"attendance.csv\", encoding = 'latin1')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Candy Data Subsection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Timestamp',\n",
       " 'Are you going actually going trick or treating yourself?',\n",
       " 'Your gender:',\n",
       " 'How old are you?',\n",
       " 'Which country do you live in?',\n",
       " 'Which state, province, county do you live in?',\n",
       " ' [100 Grand Bar]',\n",
       " ' [Anonymous brown globs that come in black and orange wrappers]',\n",
       " ' [Any full-sized candy bar]',\n",
       " ' [Black Jacks]',\n",
       " ' [Bonkers (the candy)]',\n",
       " ' [Bonkers (the board game)]',\n",
       " ' [Bottle Caps]',\n",
       " \" [Box'o'Raisins]\",\n",
       " ' [Broken glow stick]',\n",
       " ' [Butterfinger]',\n",
       " ' [Cadbury Creme Eggs]',\n",
       " ' [Candy Corn]',\n",
       " ' [Candy that is clearly just the stuff given out for free at restaurants]',\n",
       " ' [Caramellos]',\n",
       " ' [Cash, or other forms of legal tender]',\n",
       " ' [Chardonnay]',\n",
       " ' [Chick-o-Sticks (we donÍt know what that is)]',\n",
       " ' [Chiclets]',\n",
       " ' [Coffee Crisp]',\n",
       " ' [Creepy Religious comics/Chick Tracts]',\n",
       " ' [Dental paraphenalia]',\n",
       " ' [Dots]',\n",
       " ' [Dove Bars]',\n",
       " ' [Fuzzy Peaches]',\n",
       " ' [Generic Brand Acetaminophen]',\n",
       " ' [Glow sticks]',\n",
       " ' [Goo Goo Clusters]',\n",
       " \" [Good N' Plenty]\",\n",
       " ' [Gum from baseball cards]',\n",
       " ' [Gummy Bears straight up]',\n",
       " ' [Hard Candy]',\n",
       " ' [Healthy Fruit]',\n",
       " ' [Heath Bar]',\n",
       " \" [Hershey's Dark Chocolate]\",\n",
       " ' [HersheyÍs Milk Chocolate]',\n",
       " \" [Hershey's Kisses]\",\n",
       " ' [Hugs (actual physical hugs)]',\n",
       " ' [Jolly Rancher (bad flavor)]',\n",
       " ' [Jolly Ranchers (good flavor)]',\n",
       " ' [JoyJoy (Mit Iodine!)]',\n",
       " ' [Junior Mints]',\n",
       " ' [Senior Mints]',\n",
       " ' [Kale smoothie]',\n",
       " ' [Kinder Happy Hippo]',\n",
       " ' [Kit Kat]',\n",
       " ' [LaffyTaffy]',\n",
       " ' [LemonHeads]',\n",
       " ' [Licorice (not black)]',\n",
       " ' [Licorice (yes black)]',\n",
       " ' [Lindt Truffle]',\n",
       " ' [Lollipops]',\n",
       " ' [Mars]',\n",
       " ' [Mary Janes]',\n",
       " ' [Maynards]',\n",
       " ' [Mike and Ike]',\n",
       " ' [Milk Duds]',\n",
       " ' [Milky Way]',\n",
       " ' [Regular M&Ms]',\n",
       " ' [Peanut M&MÍs]',\n",
       " \" [Blue M&M's]\",\n",
       " \" [Red M&M's]\",\n",
       " \" [Third Party M&M's]\",\n",
       " ' [Minibags of chips]',\n",
       " ' [Mint Kisses]',\n",
       " ' [Mint Juleps]',\n",
       " ' [Mr. Goodbar]',\n",
       " ' [Necco Wafers]',\n",
       " ' [Nerds]',\n",
       " ' [Nestle Crunch]',\n",
       " \" [Now'n'Laters]\",\n",
       " ' [Peeps]',\n",
       " ' [Pencils]',\n",
       " ' [Person of Interest Season 3 DVD Box Set (not including Disc 4 with hilarious outtakes)]',\n",
       " ' [Pixy Stix]',\n",
       " ' [ReeseÍs Peanut Butter Cups]',\n",
       " \" [Reese's Pieces]\",\n",
       " ' [Reggie Jackson Bar]',\n",
       " ' [Rolos]',\n",
       " ' [Skittles]',\n",
       " ' [Smarties (American)]',\n",
       " ' [Smarties (Commonwealth)]',\n",
       " ' [Snickers]',\n",
       " ' [Sourpatch Kids (i.e. abominations of nature)]',\n",
       " ' [Spotted Dick]',\n",
       " ' [Starburst]',\n",
       " ' [Sweet Tarts]',\n",
       " ' [Swedish Fish]',\n",
       " ' [Sweetums (a friend to diabetes)]',\n",
       " ' [Tic Tacs]',\n",
       " ' [Those odd marshmallow circus peanut things]',\n",
       " ' [Three Musketeers]',\n",
       " ' [Tolberone something or other]',\n",
       " ' [Trail Mix]',\n",
       " ' [Twix]',\n",
       " ' [Vials of pure high fructose corn syrup, for main-lining into your vein]',\n",
       " ' [Vicodin]',\n",
       " ' [Whatchamacallit Bars]',\n",
       " ' [White Bread]',\n",
       " ' [Whole Wheat anything]',\n",
       " ' [York Peppermint Patties]',\n",
       " 'Please list any items not included above that give you JOY.',\n",
       " 'Please list any items not included above that give you DESPAIR.',\n",
       " 'Please leave any witty, snarky or thoughtful remarks or comments regarding your choices.',\n",
       " 'Guess the number of mints in my hand.',\n",
       " 'Betty or Veronica?',\n",
       " '\"That dress* that went viral a few years back - when I first saw it, it was ________\"',\n",
       " 'What is your favourite font?',\n",
       " 'Please estimate the degree(s) of separation you have from the following celebrities [JK Rowling]',\n",
       " 'Please estimate the degree(s) of separation you have from the following celebrities [JJ Abrams]',\n",
       " 'Please estimate the degree(s) of separation you have from the following celebrities [Beyonc_]',\n",
       " 'Please estimate the degree(s) of separation you have from the following celebrities [Bieber]',\n",
       " 'Please estimate the degree(s) of separation you have from the following celebrities [Kevin Bacon]',\n",
       " 'Please estimate the degree(s) of separation you have from the following celebrities [Francis Bacon (1561 - 1626)]',\n",
       " 'Which day do you prefer, Friday or Sunday?',\n",
       " 'Do you eat apples the correct way, East to West (side to side) or do you eat them like a freak of nature, South to North (bottom to top)?',\n",
       " 'When you see the above image of the 4 different websites, which one would you most likely check out (please be honest).',\n",
       " ' [York Peppermint Patties] Ignore']"
      ]
     },
     "execution_count": 1277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(dfc.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1259 entries, 0 to 1258\n",
      "Columns: 123 entries, Timestamp to  [York Peppermint Patties] Ignore\n",
      "dtypes: float64(1), object(122)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "dfc.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Are you going actually going trick or treating yourself?</th>\n",
       "      <th>Your gender:</th>\n",
       "      <th>How old are you?</th>\n",
       "      <th>Which country do you live in?</th>\n",
       "      <th>Which state, province, county do you live in?</th>\n",
       "      <th>[100 Grand Bar]</th>\n",
       "      <th>[Anonymous brown globs that come in black and orange wrappers]</th>\n",
       "      <th>[Any full-sized candy bar]</th>\n",
       "      <th>[Black Jacks]</th>\n",
       "      <th>...</th>\n",
       "      <th>Please estimate the degree(s) of separation you have from the following celebrities [JK Rowling]</th>\n",
       "      <th>Please estimate the degree(s) of separation you have from the following celebrities [JJ Abrams]</th>\n",
       "      <th>Please estimate the degree(s) of separation you have from the following celebrities [Beyonc_]</th>\n",
       "      <th>Please estimate the degree(s) of separation you have from the following celebrities [Bieber]</th>\n",
       "      <th>Please estimate the degree(s) of separation you have from the following celebrities [Kevin Bacon]</th>\n",
       "      <th>Please estimate the degree(s) of separation you have from the following celebrities [Francis Bacon (1561 - 1626)]</th>\n",
       "      <th>Which day do you prefer, Friday or Sunday?</th>\n",
       "      <th>Do you eat apples the correct way, East to West (side to side) or do you eat them like a freak of nature, South to North (bottom to top)?</th>\n",
       "      <th>When you see the above image of the 4 different websites, which one would you most likely check out (please be honest).</th>\n",
       "      <th>[York Peppermint Patties] Ignore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10/24/16 5:09</td>\n",
       "      <td>No</td>\n",
       "      <td>Male</td>\n",
       "      <td>22</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>JOY</td>\n",
       "      <td>DESPAIR</td>\n",
       "      <td>JOY</td>\n",
       "      <td>MEH</td>\n",
       "      <td>...</td>\n",
       "      <td>3 or higher</td>\n",
       "      <td>2</td>\n",
       "      <td>3 or higher</td>\n",
       "      <td>3 or higher</td>\n",
       "      <td>3 or higher</td>\n",
       "      <td>3 or higher</td>\n",
       "      <td>Friday</td>\n",
       "      <td>South to North</td>\n",
       "      <td>Science: Latest News and Headlines</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10/24/16 5:09</td>\n",
       "      <td>No</td>\n",
       "      <td>Male</td>\n",
       "      <td>45</td>\n",
       "      <td>usa</td>\n",
       "      <td>il</td>\n",
       "      <td>MEH</td>\n",
       "      <td>MEH</td>\n",
       "      <td>JOY</td>\n",
       "      <td>JOY</td>\n",
       "      <td>...</td>\n",
       "      <td>3 or higher</td>\n",
       "      <td>3 or higher</td>\n",
       "      <td>3 or higher</td>\n",
       "      <td>3 or higher</td>\n",
       "      <td>3 or higher</td>\n",
       "      <td>3 or higher</td>\n",
       "      <td>Friday</td>\n",
       "      <td>East to West</td>\n",
       "      <td>Science: Latest News and Headlines</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10/24/16 5:13</td>\n",
       "      <td>No</td>\n",
       "      <td>Female</td>\n",
       "      <td>48</td>\n",
       "      <td>US</td>\n",
       "      <td>Colorado</td>\n",
       "      <td>JOY</td>\n",
       "      <td>DESPAIR</td>\n",
       "      <td>JOY</td>\n",
       "      <td>MEH</td>\n",
       "      <td>...</td>\n",
       "      <td>3 or higher</td>\n",
       "      <td>3 or higher</td>\n",
       "      <td>3 or higher</td>\n",
       "      <td>3 or higher</td>\n",
       "      <td>3 or higher</td>\n",
       "      <td>3 or higher</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>East to West</td>\n",
       "      <td>Science: Latest News and Headlines</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10/24/16 5:14</td>\n",
       "      <td>No</td>\n",
       "      <td>Male</td>\n",
       "      <td>57</td>\n",
       "      <td>usa</td>\n",
       "      <td>il</td>\n",
       "      <td>JOY</td>\n",
       "      <td>MEH</td>\n",
       "      <td>JOY</td>\n",
       "      <td>MEH</td>\n",
       "      <td>...</td>\n",
       "      <td>3 or higher</td>\n",
       "      <td>3 or higher</td>\n",
       "      <td>3 or higher</td>\n",
       "      <td>3 or higher</td>\n",
       "      <td>3 or higher</td>\n",
       "      <td>3 or higher</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>South to North</td>\n",
       "      <td>Science: Latest News and Headlines</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10/24/16 5:14</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>USA</td>\n",
       "      <td>South Dakota</td>\n",
       "      <td>MEH</td>\n",
       "      <td>DESPAIR</td>\n",
       "      <td>JOY</td>\n",
       "      <td>DESPAIR</td>\n",
       "      <td>...</td>\n",
       "      <td>3 or higher</td>\n",
       "      <td>3 or higher</td>\n",
       "      <td>3 or higher</td>\n",
       "      <td>3 or higher</td>\n",
       "      <td>3 or higher</td>\n",
       "      <td>3 or higher</td>\n",
       "      <td>Friday</td>\n",
       "      <td>East to West</td>\n",
       "      <td>ESPN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 123 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Timestamp Are you going actually going trick or treating yourself?  \\\n",
       "0  10/24/16 5:09                                                 No         \n",
       "1  10/24/16 5:09                                                 No         \n",
       "2  10/24/16 5:13                                                 No         \n",
       "3  10/24/16 5:14                                                 No         \n",
       "4  10/24/16 5:14                                                Yes         \n",
       "\n",
       "  Your gender: How old are you? Which country do you live in?  \\\n",
       "0         Male               22                        Canada   \n",
       "1         Male               45                           usa   \n",
       "2       Female               48                            US   \n",
       "3         Male               57                           usa   \n",
       "4         Male               42                           USA   \n",
       "\n",
       "  Which state, province, county do you live in?  [100 Grand Bar]  \\\n",
       "0                                       Ontario              JOY   \n",
       "1                                            il              MEH   \n",
       "2                                      Colorado              JOY   \n",
       "3                                            il              JOY   \n",
       "4                                  South Dakota              MEH   \n",
       "\n",
       "   [Anonymous brown globs that come in black and orange wrappers]  \\\n",
       "0                                            DESPAIR                \n",
       "1                                                MEH                \n",
       "2                                            DESPAIR                \n",
       "3                                                MEH                \n",
       "4                                            DESPAIR                \n",
       "\n",
       "   [Any full-sized candy bar]  [Black Jacks]  \\\n",
       "0                         JOY            MEH   \n",
       "1                         JOY            JOY   \n",
       "2                         JOY            MEH   \n",
       "3                         JOY            MEH   \n",
       "4                         JOY        DESPAIR   \n",
       "\n",
       "                 ...                 \\\n",
       "0                ...                  \n",
       "1                ...                  \n",
       "2                ...                  \n",
       "3                ...                  \n",
       "4                ...                  \n",
       "\n",
       "  Please estimate the degree(s) of separation you have from the following celebrities [JK Rowling]  \\\n",
       "0                                        3 or higher                                                 \n",
       "1                                        3 or higher                                                 \n",
       "2                                        3 or higher                                                 \n",
       "3                                        3 or higher                                                 \n",
       "4                                        3 or higher                                                 \n",
       "\n",
       "  Please estimate the degree(s) of separation you have from the following celebrities [JJ Abrams]  \\\n",
       "0                                                  2                                                \n",
       "1                                        3 or higher                                                \n",
       "2                                        3 or higher                                                \n",
       "3                                        3 or higher                                                \n",
       "4                                        3 or higher                                                \n",
       "\n",
       "  Please estimate the degree(s) of separation you have from the following celebrities [Beyonc_]  \\\n",
       "0                                        3 or higher                                              \n",
       "1                                        3 or higher                                              \n",
       "2                                        3 or higher                                              \n",
       "3                                        3 or higher                                              \n",
       "4                                        3 or higher                                              \n",
       "\n",
       "  Please estimate the degree(s) of separation you have from the following celebrities [Bieber]  \\\n",
       "0                                        3 or higher                                             \n",
       "1                                        3 or higher                                             \n",
       "2                                        3 or higher                                             \n",
       "3                                        3 or higher                                             \n",
       "4                                        3 or higher                                             \n",
       "\n",
       "  Please estimate the degree(s) of separation you have from the following celebrities [Kevin Bacon]  \\\n",
       "0                                        3 or higher                                                  \n",
       "1                                        3 or higher                                                  \n",
       "2                                        3 or higher                                                  \n",
       "3                                        3 or higher                                                  \n",
       "4                                        3 or higher                                                  \n",
       "\n",
       "  Please estimate the degree(s) of separation you have from the following celebrities [Francis Bacon (1561 - 1626)]  \\\n",
       "0                                        3 or higher                                                                  \n",
       "1                                        3 or higher                                                                  \n",
       "2                                        3 or higher                                                                  \n",
       "3                                        3 or higher                                                                  \n",
       "4                                        3 or higher                                                                  \n",
       "\n",
       "  Which day do you prefer, Friday or Sunday?  \\\n",
       "0                                     Friday   \n",
       "1                                     Friday   \n",
       "2                                     Sunday   \n",
       "3                                     Sunday   \n",
       "4                                     Friday   \n",
       "\n",
       "  Do you eat apples the correct way, East to West (side to side) or do you eat them like a freak of nature, South to North (bottom to top)?  \\\n",
       "0                                     South to North                                                                                          \n",
       "1                                       East to West                                                                                          \n",
       "2                                       East to West                                                                                          \n",
       "3                                     South to North                                                                                          \n",
       "4                                       East to West                                                                                          \n",
       "\n",
       "  When you see the above image of the 4 different websites, which one would you most likely check out (please be honest).  \\\n",
       "0                 Science: Latest News and Headlines                                                                        \n",
       "1                 Science: Latest News and Headlines                                                                        \n",
       "2                 Science: Latest News and Headlines                                                                        \n",
       "3                 Science: Latest News and Headlines                                                                        \n",
       "4                                               ESPN                                                                        \n",
       "\n",
       "   [York Peppermint Patties] Ignore  \n",
       "0                               NaN  \n",
       "1                               NaN  \n",
       "2                               NaN  \n",
       "3                               NaN  \n",
       "4                               NaN  \n",
       "\n",
       "[5 rows x 123 columns]"
      ]
     },
     "execution_count": 1279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attendance Data Subsection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Table 43. Average daily attendance (ADA) as a percentage of total enrollment, school day length, and school year length in public schools, by school level and state: 2007-08',\n",
       " 'Unnamed: 1',\n",
       " 'Unnamed: 2',\n",
       " 'Unnamed: 3',\n",
       " 'Unnamed: 4',\n",
       " 'Unnamed: 5',\n",
       " 'Unnamed: 6',\n",
       " 'Unnamed: 7',\n",
       " 'Unnamed: 8',\n",
       " 'Unnamed: 9',\n",
       " 'Unnamed: 10',\n",
       " 'Unnamed: 11',\n",
       " 'Unnamed: 12',\n",
       " 'Unnamed: 13',\n",
       " 'Unnamed: 14',\n",
       " 'Unnamed: 15',\n",
       " 'Unnamed: 16']"
      ]
     },
     "execution_count": 1280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(dfa.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 68 entries, 0 to 67\n",
      "Data columns (total 17 columns):\n",
      "Table 43. Average daily attendance (ADA) as a percentage of total enrollment, school day length, and school year length in public schools, by school level and state: 2007-08    57 non-null object\n",
      "Unnamed: 1                                                                                                                                                                       55 non-null object\n",
      "Unnamed: 2                                                                                                                                                                       52 non-null object\n",
      "Unnamed: 3                                                                                                                                                                       54 non-null object\n",
      "Unnamed: 4                                                                                                                                                                       52 non-null object\n",
      "Unnamed: 5                                                                                                                                                                       54 non-null object\n",
      "Unnamed: 6                                                                                                                                                                       52 non-null object\n",
      "Unnamed: 7                                                                                                                                                                       54 non-null object\n",
      "Unnamed: 8                                                                                                                                                                       52 non-null object\n",
      "Unnamed: 9                                                                                                                                                                       55 non-null object\n",
      "Unnamed: 10                                                                                                                                                                      52 non-null object\n",
      "Unnamed: 11                                                                                                                                                                      54 non-null object\n",
      "Unnamed: 12                                                                                                                                                                      52 non-null object\n",
      "Unnamed: 13                                                                                                                                                                      55 non-null object\n",
      "Unnamed: 14                                                                                                                                                                      52 non-null object\n",
      "Unnamed: 15                                                                                                                                                                      54 non-null object\n",
      "Unnamed: 16                                                                                                                                                                      52 non-null object\n",
      "dtypes: object(17)\n",
      "memory usage: 9.1+ KB\n"
     ]
    }
   ],
   "source": [
    "dfa.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Table 43. Average daily attendance (ADA) as a percentage of total enrollment, school day length, and school year length in public schools, by school level and state: 2007-08</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>Unnamed: 10</th>\n",
       "      <th>Unnamed: 11</th>\n",
       "      <th>Unnamed: 12</th>\n",
       "      <th>Unnamed: 13</th>\n",
       "      <th>Unnamed: 14</th>\n",
       "      <th>Unnamed: 15</th>\n",
       "      <th>Unnamed: 16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Total elementary, secondary, and combined elem...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Elementary schools</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Secondary schools</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ADA as percent of enrollment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Average hours in school day</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Average days in school year</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Average hours in school year</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ADA as percent of enrollment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Average hours in school day</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ADA as percent of enrollment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Average hours in school day</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>United States ........</td>\n",
       "      <td>93.1</td>\n",
       "      <td>(0.22)</td>\n",
       "      <td>6.6</td>\n",
       "      <td>(0.02)</td>\n",
       "      <td>180</td>\n",
       "      <td>(0.1)</td>\n",
       "      <td>1,193</td>\n",
       "      <td>(3.1)</td>\n",
       "      <td>94.0</td>\n",
       "      <td>(0.27)</td>\n",
       "      <td>6.7</td>\n",
       "      <td>(0.02)</td>\n",
       "      <td>91.1</td>\n",
       "      <td>(0.43)</td>\n",
       "      <td>6.6</td>\n",
       "      <td>(0.04)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alabama .................</td>\n",
       "      <td>93.8</td>\n",
       "      <td>(1.24)</td>\n",
       "      <td>7.0</td>\n",
       "      <td>(0.07)</td>\n",
       "      <td>180</td>\n",
       "      <td>(0.8)</td>\n",
       "      <td>1,267</td>\n",
       "      <td>(12.3)</td>\n",
       "      <td>93.8</td>\n",
       "      <td>(1.84)</td>\n",
       "      <td>7.0</td>\n",
       "      <td>(0.08)</td>\n",
       "      <td>94.6</td>\n",
       "      <td>(0.38)</td>\n",
       "      <td>7.1</td>\n",
       "      <td>(0.17)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Table 43. Average daily attendance (ADA) as a percentage of total enrollment, school day length, and school year length in public schools, by school level and state: 2007-08  \\\n",
       "0                                                NaN                                                                                                                              \n",
       "1                                                NaN                                                                                                                              \n",
       "2                                                  1                                                                                                                              \n",
       "3                             United States ........                                                                                                                              \n",
       "4                          Alabama .................                                                                                                                              \n",
       "\n",
       "                                          Unnamed: 1 Unnamed: 2  \\\n",
       "0  Total elementary, secondary, and combined elem...        NaN   \n",
       "1                       ADA as percent of enrollment        NaN   \n",
       "2                                                  2        NaN   \n",
       "3                                               93.1     (0.22)   \n",
       "4                                               93.8     (1.24)   \n",
       "\n",
       "                    Unnamed: 3 Unnamed: 4                   Unnamed: 5  \\\n",
       "0                          NaN        NaN                          NaN   \n",
       "1  Average hours in school day        NaN  Average days in school year   \n",
       "2                            3        NaN                            4   \n",
       "3                          6.6     (0.02)                          180   \n",
       "4                          7.0     (0.07)                          180   \n",
       "\n",
       "  Unnamed: 6                    Unnamed: 7 Unnamed: 8  \\\n",
       "0        NaN                           NaN        NaN   \n",
       "1        NaN  Average hours in school year        NaN   \n",
       "2        NaN                             5        NaN   \n",
       "3      (0.1)                         1,193      (3.1)   \n",
       "4      (0.8)                         1,267     (12.3)   \n",
       "\n",
       "                     Unnamed: 9 Unnamed: 10                  Unnamed: 11  \\\n",
       "0            Elementary schools         NaN                          NaN   \n",
       "1  ADA as percent of enrollment         NaN  Average hours in school day   \n",
       "2                             6         NaN                            7   \n",
       "3                          94.0      (0.27)                          6.7   \n",
       "4                          93.8      (1.84)                          7.0   \n",
       "\n",
       "  Unnamed: 12                   Unnamed: 13 Unnamed: 14  \\\n",
       "0         NaN             Secondary schools         NaN   \n",
       "1         NaN  ADA as percent of enrollment         NaN   \n",
       "2         NaN                             8         NaN   \n",
       "3      (0.02)                          91.1      (0.43)   \n",
       "4      (0.08)                          94.6      (0.38)   \n",
       "\n",
       "                   Unnamed: 15 Unnamed: 16  \n",
       "0                          NaN         NaN  \n",
       "1  Average hours in school day         NaN  \n",
       "2                            9         NaN  \n",
       "3                          6.6      (0.04)  \n",
       "4                          7.1      (0.17)  "
      ]
     },
     "execution_count": 1282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfa.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sales Data Subsection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Unnamed: 0',\n",
       " 'event_id',\n",
       " 'primary_act_id',\n",
       " 'secondary_act_id',\n",
       " 'purch_party_lkup_id',\n",
       " 'event_name',\n",
       " 'primary_act_name',\n",
       " 'secondary_act_name',\n",
       " 'major_cat_name',\n",
       " 'minor_cat_name',\n",
       " 'la_event_type_cat',\n",
       " 'event_disp_name',\n",
       " 'ticket_text',\n",
       " 'tickets_purchased_qty',\n",
       " 'trans_face_val_amt',\n",
       " 'delivery_type_cd',\n",
       " 'event_date_time',\n",
       " 'event_dt',\n",
       " 'presale_dt',\n",
       " 'onsale_dt',\n",
       " 'sales_ord_create_dttm',\n",
       " 'sales_ord_tran_dt',\n",
       " 'print_dt',\n",
       " 'timezn_nm',\n",
       " 'venue_city',\n",
       " 'venue_state',\n",
       " 'venue_postal_cd_sgmt_1',\n",
       " 'sales_platform_cd',\n",
       " 'print_flg',\n",
       " 'la_valid_tkt_event_flg',\n",
       " 'fin_mkt_nm',\n",
       " 'web_session_cookie_val',\n",
       " 'gndr_cd',\n",
       " 'age_yr',\n",
       " 'income_amt',\n",
       " 'edu_val',\n",
       " 'edu_1st_indv_val',\n",
       " 'edu_2nd_indv_val',\n",
       " 'adults_in_hh_num',\n",
       " 'married_ind',\n",
       " 'child_present_ind',\n",
       " 'home_owner_ind',\n",
       " 'occpn_val',\n",
       " 'occpn_1st_val',\n",
       " 'occpn_2nd_val',\n",
       " 'dist_to_ven']"
      ]
     },
     "execution_count": 1283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(dfs.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 46 columns):\n",
      "Unnamed: 0                5000 non-null int64\n",
      "event_id                  5000 non-null object\n",
      "primary_act_id            5000 non-null object\n",
      "secondary_act_id          5000 non-null object\n",
      "purch_party_lkup_id       5000 non-null object\n",
      "event_name                5000 non-null object\n",
      "primary_act_name          5000 non-null object\n",
      "secondary_act_name        1586 non-null object\n",
      "major_cat_name            5000 non-null object\n",
      "minor_cat_name            5000 non-null object\n",
      "la_event_type_cat         5000 non-null object\n",
      "event_disp_name           5000 non-null object\n",
      "ticket_text               5000 non-null object\n",
      "tickets_purchased_qty     5000 non-null int64\n",
      "trans_face_val_amt        5000 non-null float64\n",
      "delivery_type_cd          5000 non-null object\n",
      "event_date_time           5000 non-null object\n",
      "event_dt                  5000 non-null object\n",
      "presale_dt                2108 non-null object\n",
      "onsale_dt                 4899 non-null object\n",
      "sales_ord_create_dttm     4996 non-null object\n",
      "sales_ord_tran_dt         5000 non-null object\n",
      "print_dt                  4576 non-null object\n",
      "timezn_nm                 5000 non-null object\n",
      "venue_city                5000 non-null object\n",
      "venue_state               5000 non-null object\n",
      "venue_postal_cd_sgmt_1    5000 non-null object\n",
      "sales_platform_cd         2578 non-null object\n",
      "print_flg                 5000 non-null object\n",
      "la_valid_tkt_event_flg    5000 non-null object\n",
      "fin_mkt_nm                5000 non-null object\n",
      "web_session_cookie_val    5000 non-null object\n",
      "gndr_cd                   177 non-null object\n",
      "age_yr                    168 non-null float64\n",
      "income_amt                154 non-null float64\n",
      "edu_val                   139 non-null object\n",
      "edu_1st_indv_val          112 non-null object\n",
      "edu_2nd_indv_val          86 non-null object\n",
      "adults_in_hh_num          176 non-null float64\n",
      "married_ind               157 non-null float64\n",
      "child_present_ind         130 non-null float64\n",
      "home_owner_ind            138 non-null float64\n",
      "occpn_val                 79 non-null object\n",
      "occpn_1st_val             77 non-null object\n",
      "occpn_2nd_val             63 non-null object\n",
      "dist_to_ven               323 non-null float64\n",
      "dtypes: float64(8), int64(2), object(36)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "source": [
    "dfs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>event_id</th>\n",
       "      <th>primary_act_id</th>\n",
       "      <th>secondary_act_id</th>\n",
       "      <th>purch_party_lkup_id</th>\n",
       "      <th>event_name</th>\n",
       "      <th>primary_act_name</th>\n",
       "      <th>secondary_act_name</th>\n",
       "      <th>major_cat_name</th>\n",
       "      <th>minor_cat_name</th>\n",
       "      <th>...</th>\n",
       "      <th>edu_1st_indv_val</th>\n",
       "      <th>edu_2nd_indv_val</th>\n",
       "      <th>adults_in_hh_num</th>\n",
       "      <th>married_ind</th>\n",
       "      <th>child_present_ind</th>\n",
       "      <th>home_owner_ind</th>\n",
       "      <th>occpn_val</th>\n",
       "      <th>occpn_1st_val</th>\n",
       "      <th>occpn_2nd_val</th>\n",
       "      <th>dist_to_ven</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>abcaf1adb99a935fc661</td>\n",
       "      <td>43f0436b905bfa7c2eec</td>\n",
       "      <td>b85143bf51323b72e53c</td>\n",
       "      <td>7dfa56dd7d5956b17587</td>\n",
       "      <td>Xfinity Center Mansfield Premier Parking: Flor...</td>\n",
       "      <td>XFINITY Center Mansfield Premier Parking</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MISC</td>\n",
       "      <td>PARKING</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>6c56d7f08c95f2aa453c</td>\n",
       "      <td>1a3e9aecd0617706a794</td>\n",
       "      <td>f53529c5679ea6ca5a48</td>\n",
       "      <td>4f9e6fc637eaf7b736c2</td>\n",
       "      <td>Gorge Camping - dave matthews band - sept 3-7</td>\n",
       "      <td>Gorge Camping</td>\n",
       "      <td>Dave Matthews Band</td>\n",
       "      <td>MISC</td>\n",
       "      <td>CAMPING</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>c7ab4524a121f9d687d2</td>\n",
       "      <td>4b677c3f5bec71eec8d1</td>\n",
       "      <td>b85143bf51323b72e53c</td>\n",
       "      <td>6c2545703bd527a7144d</td>\n",
       "      <td>Dodge Theatre Adams Street Parking - benise</td>\n",
       "      <td>Parking Event</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MISC</td>\n",
       "      <td>PARKING</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>394cb493f893be9b9ed1</td>\n",
       "      <td>b1ccea01ad6ef8522796</td>\n",
       "      <td>b85143bf51323b72e53c</td>\n",
       "      <td>527d6b1eaffc69ddd882</td>\n",
       "      <td>Gexa Energy Pavilion Vip Parking : kid rock wi...</td>\n",
       "      <td>Gexa Energy Pavilion VIP Parking</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MISC</td>\n",
       "      <td>PARKING</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>55b5f67e618557929f48</td>\n",
       "      <td>91c03a34b562436efa3c</td>\n",
       "      <td>b85143bf51323b72e53c</td>\n",
       "      <td>8bd62c394a35213bdf52</td>\n",
       "      <td>Premier Parking - motley crue</td>\n",
       "      <td>White River Amphitheatre Premier Parking</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MISC</td>\n",
       "      <td>PARKING</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0              event_id        primary_act_id  \\\n",
       "0           1  abcaf1adb99a935fc661  43f0436b905bfa7c2eec   \n",
       "1           2  6c56d7f08c95f2aa453c  1a3e9aecd0617706a794   \n",
       "2           3  c7ab4524a121f9d687d2  4b677c3f5bec71eec8d1   \n",
       "3           4  394cb493f893be9b9ed1  b1ccea01ad6ef8522796   \n",
       "4           5  55b5f67e618557929f48  91c03a34b562436efa3c   \n",
       "\n",
       "       secondary_act_id   purch_party_lkup_id  \\\n",
       "0  b85143bf51323b72e53c  7dfa56dd7d5956b17587   \n",
       "1  f53529c5679ea6ca5a48  4f9e6fc637eaf7b736c2   \n",
       "2  b85143bf51323b72e53c  6c2545703bd527a7144d   \n",
       "3  b85143bf51323b72e53c  527d6b1eaffc69ddd882   \n",
       "4  b85143bf51323b72e53c  8bd62c394a35213bdf52   \n",
       "\n",
       "                                          event_name  \\\n",
       "0  Xfinity Center Mansfield Premier Parking: Flor...   \n",
       "1      Gorge Camping - dave matthews band - sept 3-7   \n",
       "2        Dodge Theatre Adams Street Parking - benise   \n",
       "3  Gexa Energy Pavilion Vip Parking : kid rock wi...   \n",
       "4                      Premier Parking - motley crue   \n",
       "\n",
       "                           primary_act_name  secondary_act_name  \\\n",
       "0  XFINITY Center Mansfield Premier Parking                 NaN   \n",
       "1                             Gorge Camping  Dave Matthews Band   \n",
       "2                             Parking Event                 NaN   \n",
       "3          Gexa Energy Pavilion VIP Parking                 NaN   \n",
       "4  White River Amphitheatre Premier Parking                 NaN   \n",
       "\n",
       "  major_cat_name minor_cat_name     ...     edu_1st_indv_val edu_2nd_indv_val  \\\n",
       "0           MISC        PARKING     ...                  NaN              NaN   \n",
       "1           MISC        CAMPING     ...                  NaN              NaN   \n",
       "2           MISC        PARKING     ...                  NaN              NaN   \n",
       "3           MISC        PARKING     ...                  NaN              NaN   \n",
       "4           MISC        PARKING     ...                  NaN              NaN   \n",
       "\n",
       "  adults_in_hh_num  married_ind  child_present_ind home_owner_ind occpn_val  \\\n",
       "0              NaN          NaN                NaN            NaN       NaN   \n",
       "1              NaN          NaN                NaN            NaN       NaN   \n",
       "2              NaN          NaN                NaN            NaN       NaN   \n",
       "3              NaN          NaN                NaN            NaN       NaN   \n",
       "4              NaN          NaN                NaN            NaN       NaN   \n",
       "\n",
       "  occpn_1st_val occpn_2nd_val dist_to_ven  \n",
       "0           NaN           NaN         NaN  \n",
       "1           NaN           NaN        59.0  \n",
       "2           NaN           NaN         NaN  \n",
       "3           NaN           NaN         NaN  \n",
       "4           NaN           NaN         NaN  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 1285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction 2:\n",
    "\n",
    "In this lab, I have decided to use the Boing-Boing candy data and the sales data due as a result of the information acquired above. By doing df.column for all of the different data sets, I was able to find out the names of the indivdual columns and gain an insight to the data. From this function, I was able to find out the contents of the data and, I found that attendance did not have any column names. I also used .head() in order to glimpse the first few rows of data. \n",
    "\n",
    "I decided to clean attendance and candy data, primarily due to the results from the function .head(). When I used the head function on sales data, i noticed that the majority of data in the columns was either NaN, strings of letters and numbers that were difficult to decipher OR, made no sense under the column they were put in. For example, under the column \"event_name\", one of the resulting data entries was \"Xfinity Center\" or \"Mansfield\". \n",
    "\n",
    "In order to have an easier time cleaning data, I decided to exclude sales data, leaving me with the attendance and Boing-Boing Candy data to clean for the lab.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Preparation 1 - Boing-Boing Candy Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Are you going actually going trick or treating yourself?</th>\n",
       "      <th>Your gender:</th>\n",
       "      <th>How old are you?</th>\n",
       "      <th>Which country do you live in?</th>\n",
       "      <th>Which state, province, county do you live in?</th>\n",
       "      <th>[100 Grand Bar]</th>\n",
       "      <th>[Anonymous brown globs that come in black and orange wrappers]</th>\n",
       "      <th>[Any full-sized candy bar]</th>\n",
       "      <th>[Black Jacks]</th>\n",
       "      <th>...</th>\n",
       "      <th>Please estimate the degree(s) of separation you have from the following celebrities [JK Rowling]</th>\n",
       "      <th>Please estimate the degree(s) of separation you have from the following celebrities [JJ Abrams]</th>\n",
       "      <th>Please estimate the degree(s) of separation you have from the following celebrities [Beyonc_]</th>\n",
       "      <th>Please estimate the degree(s) of separation you have from the following celebrities [Bieber]</th>\n",
       "      <th>Please estimate the degree(s) of separation you have from the following celebrities [Kevin Bacon]</th>\n",
       "      <th>Please estimate the degree(s) of separation you have from the following celebrities [Francis Bacon (1561 - 1626)]</th>\n",
       "      <th>Which day do you prefer, Friday or Sunday?</th>\n",
       "      <th>Do you eat apples the correct way, East to West (side to side) or do you eat them like a freak of nature, South to North (bottom to top)?</th>\n",
       "      <th>When you see the above image of the 4 different websites, which one would you most likely check out (please be honest).</th>\n",
       "      <th>[York Peppermint Patties] Ignore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10/24/16 5:09</td>\n",
       "      <td>No</td>\n",
       "      <td>Male</td>\n",
       "      <td>22</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>JOY</td>\n",
       "      <td>DESPAIR</td>\n",
       "      <td>JOY</td>\n",
       "      <td>MEH</td>\n",
       "      <td>...</td>\n",
       "      <td>3 or higher</td>\n",
       "      <td>2</td>\n",
       "      <td>3 or higher</td>\n",
       "      <td>3 or higher</td>\n",
       "      <td>3 or higher</td>\n",
       "      <td>3 or higher</td>\n",
       "      <td>Friday</td>\n",
       "      <td>South to North</td>\n",
       "      <td>Science: Latest News and Headlines</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10/24/16 5:09</td>\n",
       "      <td>No</td>\n",
       "      <td>Male</td>\n",
       "      <td>45</td>\n",
       "      <td>usa</td>\n",
       "      <td>il</td>\n",
       "      <td>MEH</td>\n",
       "      <td>MEH</td>\n",
       "      <td>JOY</td>\n",
       "      <td>JOY</td>\n",
       "      <td>...</td>\n",
       "      <td>3 or higher</td>\n",
       "      <td>3 or higher</td>\n",
       "      <td>3 or higher</td>\n",
       "      <td>3 or higher</td>\n",
       "      <td>3 or higher</td>\n",
       "      <td>3 or higher</td>\n",
       "      <td>Friday</td>\n",
       "      <td>East to West</td>\n",
       "      <td>Science: Latest News and Headlines</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10/24/16 5:13</td>\n",
       "      <td>No</td>\n",
       "      <td>Female</td>\n",
       "      <td>48</td>\n",
       "      <td>US</td>\n",
       "      <td>Colorado</td>\n",
       "      <td>JOY</td>\n",
       "      <td>DESPAIR</td>\n",
       "      <td>JOY</td>\n",
       "      <td>MEH</td>\n",
       "      <td>...</td>\n",
       "      <td>3 or higher</td>\n",
       "      <td>3 or higher</td>\n",
       "      <td>3 or higher</td>\n",
       "      <td>3 or higher</td>\n",
       "      <td>3 or higher</td>\n",
       "      <td>3 or higher</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>East to West</td>\n",
       "      <td>Science: Latest News and Headlines</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10/24/16 5:14</td>\n",
       "      <td>No</td>\n",
       "      <td>Male</td>\n",
       "      <td>57</td>\n",
       "      <td>usa</td>\n",
       "      <td>il</td>\n",
       "      <td>JOY</td>\n",
       "      <td>MEH</td>\n",
       "      <td>JOY</td>\n",
       "      <td>MEH</td>\n",
       "      <td>...</td>\n",
       "      <td>3 or higher</td>\n",
       "      <td>3 or higher</td>\n",
       "      <td>3 or higher</td>\n",
       "      <td>3 or higher</td>\n",
       "      <td>3 or higher</td>\n",
       "      <td>3 or higher</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>South to North</td>\n",
       "      <td>Science: Latest News and Headlines</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10/24/16 5:14</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>USA</td>\n",
       "      <td>South Dakota</td>\n",
       "      <td>MEH</td>\n",
       "      <td>DESPAIR</td>\n",
       "      <td>JOY</td>\n",
       "      <td>DESPAIR</td>\n",
       "      <td>...</td>\n",
       "      <td>3 or higher</td>\n",
       "      <td>3 or higher</td>\n",
       "      <td>3 or higher</td>\n",
       "      <td>3 or higher</td>\n",
       "      <td>3 or higher</td>\n",
       "      <td>3 or higher</td>\n",
       "      <td>Friday</td>\n",
       "      <td>East to West</td>\n",
       "      <td>ESPN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 123 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Timestamp Are you going actually going trick or treating yourself?  \\\n",
       "0  10/24/16 5:09                                                 No         \n",
       "1  10/24/16 5:09                                                 No         \n",
       "2  10/24/16 5:13                                                 No         \n",
       "3  10/24/16 5:14                                                 No         \n",
       "4  10/24/16 5:14                                                Yes         \n",
       "\n",
       "  Your gender: How old are you? Which country do you live in?  \\\n",
       "0         Male               22                        Canada   \n",
       "1         Male               45                           usa   \n",
       "2       Female               48                            US   \n",
       "3         Male               57                           usa   \n",
       "4         Male               42                           USA   \n",
       "\n",
       "  Which state, province, county do you live in?  [100 Grand Bar]  \\\n",
       "0                                       Ontario              JOY   \n",
       "1                                            il              MEH   \n",
       "2                                      Colorado              JOY   \n",
       "3                                            il              JOY   \n",
       "4                                  South Dakota              MEH   \n",
       "\n",
       "   [Anonymous brown globs that come in black and orange wrappers]  \\\n",
       "0                                            DESPAIR                \n",
       "1                                                MEH                \n",
       "2                                            DESPAIR                \n",
       "3                                                MEH                \n",
       "4                                            DESPAIR                \n",
       "\n",
       "   [Any full-sized candy bar]  [Black Jacks]  \\\n",
       "0                         JOY            MEH   \n",
       "1                         JOY            JOY   \n",
       "2                         JOY            MEH   \n",
       "3                         JOY            MEH   \n",
       "4                         JOY        DESPAIR   \n",
       "\n",
       "                 ...                 \\\n",
       "0                ...                  \n",
       "1                ...                  \n",
       "2                ...                  \n",
       "3                ...                  \n",
       "4                ...                  \n",
       "\n",
       "  Please estimate the degree(s) of separation you have from the following celebrities [JK Rowling]  \\\n",
       "0                                        3 or higher                                                 \n",
       "1                                        3 or higher                                                 \n",
       "2                                        3 or higher                                                 \n",
       "3                                        3 or higher                                                 \n",
       "4                                        3 or higher                                                 \n",
       "\n",
       "  Please estimate the degree(s) of separation you have from the following celebrities [JJ Abrams]  \\\n",
       "0                                                  2                                                \n",
       "1                                        3 or higher                                                \n",
       "2                                        3 or higher                                                \n",
       "3                                        3 or higher                                                \n",
       "4                                        3 or higher                                                \n",
       "\n",
       "  Please estimate the degree(s) of separation you have from the following celebrities [Beyonc_]  \\\n",
       "0                                        3 or higher                                              \n",
       "1                                        3 or higher                                              \n",
       "2                                        3 or higher                                              \n",
       "3                                        3 or higher                                              \n",
       "4                                        3 or higher                                              \n",
       "\n",
       "  Please estimate the degree(s) of separation you have from the following celebrities [Bieber]  \\\n",
       "0                                        3 or higher                                             \n",
       "1                                        3 or higher                                             \n",
       "2                                        3 or higher                                             \n",
       "3                                        3 or higher                                             \n",
       "4                                        3 or higher                                             \n",
       "\n",
       "  Please estimate the degree(s) of separation you have from the following celebrities [Kevin Bacon]  \\\n",
       "0                                        3 or higher                                                  \n",
       "1                                        3 or higher                                                  \n",
       "2                                        3 or higher                                                  \n",
       "3                                        3 or higher                                                  \n",
       "4                                        3 or higher                                                  \n",
       "\n",
       "  Please estimate the degree(s) of separation you have from the following celebrities [Francis Bacon (1561 - 1626)]  \\\n",
       "0                                        3 or higher                                                                  \n",
       "1                                        3 or higher                                                                  \n",
       "2                                        3 or higher                                                                  \n",
       "3                                        3 or higher                                                                  \n",
       "4                                        3 or higher                                                                  \n",
       "\n",
       "  Which day do you prefer, Friday or Sunday?  \\\n",
       "0                                     Friday   \n",
       "1                                     Friday   \n",
       "2                                     Sunday   \n",
       "3                                     Sunday   \n",
       "4                                     Friday   \n",
       "\n",
       "  Do you eat apples the correct way, East to West (side to side) or do you eat them like a freak of nature, South to North (bottom to top)?  \\\n",
       "0                                     South to North                                                                                          \n",
       "1                                       East to West                                                                                          \n",
       "2                                       East to West                                                                                          \n",
       "3                                     South to North                                                                                          \n",
       "4                                       East to West                                                                                          \n",
       "\n",
       "  When you see the above image of the 4 different websites, which one would you most likely check out (please be honest).  \\\n",
       "0                 Science: Latest News and Headlines                                                                        \n",
       "1                 Science: Latest News and Headlines                                                                        \n",
       "2                 Science: Latest News and Headlines                                                                        \n",
       "3                 Science: Latest News and Headlines                                                                        \n",
       "4                                               ESPN                                                                        \n",
       "\n",
       "   [York Peppermint Patties] Ignore  \n",
       "0                               NaN  \n",
       "1                               NaN  \n",
       "2                               NaN  \n",
       "3                               NaN  \n",
       "4                               NaN  \n",
       "\n",
       "[5 rows x 123 columns]"
      ]
     },
     "execution_count": 1286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Canada', 'usa', 'US', 'USA', 'UK', 'United States of America',\n",
       "       'uSA', 'Japan', 'united states', 'USA ', 'canada', 'United States',\n",
       "       'us', 'france', 'USSA', 'United States of America ', 'U.S.A.',\n",
       "       'A tropical island south of the equator', 'england', 'uk',\n",
       "       'Switzerland', 'Murica', 'United Kingdom', 'Neverland', 'USA!',\n",
       "       'this one',\n",
       "       \"USA (I think but it's an election year so who can really tell)\",\n",
       "       'Korea', '51', 'Usa', nan, 'U.S.', 'Us', 'America ',\n",
       "       'Units States', 'belgium', 'croatia', 'United states', 'Portugal',\n",
       "       'England', 'USA USA USA', 'the best one - usa', 'USA! USA! USA!',\n",
       "       '47', 'united states ', 'Cascadia', 'espaÐa', 'u.s.',\n",
       "       \"there isn't one for old men\", 'United States ', 'Panama',\n",
       "       'one of the best ones', 'The Yoo Ess of Aaayyyyyy',\n",
       "       'United Kindom', 'France', 'America', 'Australia', 'hungary',\n",
       "       'united states of america', 'UK ', 'Austria', 'Somewhere',\n",
       "       'New Zealand', '54', 'Germany', 'Mexico', '44', 'Brasil',\n",
       "       \"god's country\", 'South Korea', 'USA!!!!!!', 'Philippines',\n",
       "       ' United States', 'EUA', 'USA! USA!', '45', 'sweden', 'Canada ',\n",
       "       'United Sates', \"Sub-Canadian North America... 'Merica\",\n",
       "       'The Netherlands', 'Finland', 'Trumpistan', 'U.s.', 'Merica',\n",
       "       'China', 'germany', 'See above', 'UNited States', 'kenya', '30',\n",
       "       'Netherlands', 'The republic of Cascadia ', 'United Stetes',\n",
       "       'america', 'Not the USA or Canada', 'USA USA USA USA',\n",
       "       'New Zealand ', 'United  States of America', 'netherlands',\n",
       "       'Denial', 'United State'], dtype=object)"
      ]
     },
     "execution_count": 1287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_list = dfc[\"Which country do you live in?\"].unique()\n",
    "country_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1288,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['canada', 'usa', 'us', 'uk', 'united states of america', 'japan',\n",
       "       'united states', 'usa ', 'france', 'ussa',\n",
       "       'united states of america ', 'u.s.a.',\n",
       "       'a tropical island south of the equator', 'england', 'switzerland',\n",
       "       'murica', 'united kingdom', 'neverland', 'usa!', 'this one',\n",
       "       \"usa (i think but it's an election year so who can really tell)\",\n",
       "       'korea', '51', nan, 'u.s.', 'america ', 'units states', 'belgium',\n",
       "       'croatia', 'portugal', 'usa usa usa', 'the best one - usa',\n",
       "       'usa! usa! usa!', '47', 'united states ', 'cascadia', 'espaða',\n",
       "       \"there isn't one for old men\", 'panama', 'one of the best ones',\n",
       "       'the yoo ess of aaayyyyyy', 'united kindom', 'america',\n",
       "       'australia', 'hungary', 'uk ', 'austria', 'somewhere',\n",
       "       'new zealand', '54', 'germany', 'mexico', '44', 'brasil',\n",
       "       \"god's country\", 'south korea', 'usa!!!!!!', 'philippines',\n",
       "       ' united states', 'eua', 'usa! usa!', '45', 'sweden', 'canada ',\n",
       "       'united sates', \"sub-canadian north america... 'merica\",\n",
       "       'the netherlands', 'finland', 'trumpistan', 'merica', 'china',\n",
       "       'see above', 'kenya', '30', 'netherlands',\n",
       "       'the republic of cascadia ', 'united stetes',\n",
       "       'not the usa or canada', 'usa usa usa usa', 'new zealand ',\n",
       "       'united  states of america', 'denial', 'united state'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 1288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#I am just converting all strings into lowercase so that \n",
    "\n",
    "\n",
    "dfc[\"Which country do you live in?\"] = dfc[\"Which country do you live in?\"].str.lower()\n",
    "dfc[\"Which country do you live in?\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1289,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here, I am just removing all blank spaces in the data just to make my life a whole lot easier and to make what comes\n",
    "#less difficult. \n",
    "\n",
    "dfc[\"Which country do you live in?\"] = dfc[\"Which country do you live in?\"].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1290,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Here, I am equating all string values with specific sub-strings (so that i dont have to type the whole string\n",
    "#when using the .replace function). I am basically taking the easy route and locating all string values with certain\n",
    "#short string sequences and then replacing the whole string with what the actual value should be. In this case, I chose\n",
    "#their corresponding alpha-3 codes for each country because I think that makes the data look neat and is fairly \n",
    "#recognizable and, the 3 digit codes are less confusing than the 2 digit codes which can be confused for states. \n",
    "\n",
    "dfc.loc[dfc['Which country do you live in?'].str.contains('usa', na=False), 'Which country do you live in?'] = 'USA'\n",
    "dfc.loc[dfc['Which country do you live in?'].str.contains('america', na=False), 'Which country do you live in?'] = 'USA'\n",
    "dfc.loc[dfc['Which country do you live in?'].str.contains('states', na=False), 'Which country do you live in?'] = 'USA'\n",
    "dfc.loc[dfc['Which country do you live in?'].str.contains('usa', na=False), 'Which country do you live in?'] = 'USA'\n",
    "dfc.loc[dfc['Which country do you live in?'].str.contains('korea', na=False), 'Which country do you live in?'] = 'kr'\n",
    "dfc.loc[dfc['Which country do you live in?'].str.contains('zealand', na=False), 'Which country do you live in?'] = 'nz'\n",
    "dfc.loc[dfc['Which country do you live in?'].str.contains('canada', na=False), 'Which country do you live in?'] = 'can'\n",
    "dfc.loc[dfc['Which country do you live in?'].str.contains('netherlands', na=False), 'Which country do you live in?'] = 'nld'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1291,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here, I am just replacing values that I cannot use the .contains function for with the corresponding alpha-3 \n",
    "#sequence.\n",
    "\n",
    "dfc[\"Which country do you live in?\"] = dfc[\"Which country do you live in?\"].str.replace('the yoo ess of aaayyyyyy', 'USA')\n",
    "dfc[\"Which country do you live in?\"] = dfc[\"Which country do you live in?\"].str.replace('ussa', 'USA')\n",
    "dfc[\"Which country do you live in?\"] = dfc[\"Which country do you live in?\"].str.replace('u.s.a.', 'USA')\n",
    "dfc[\"Which country do you live in?\"] = dfc[\"Which country do you live in?\"].str.replace('united stetes', 'USA')\n",
    "dfc[\"Which country do you live in?\"] = dfc[\"Which country do you live in?\"].str.replace('united state', 'USA')\n",
    "dfc[\"Which country do you live in?\"] = dfc[\"Which country do you live in?\"].str.replace('u.s.', 'USA')\n",
    "dfc[\"Which country do you live in?\"] = dfc[\"Which country do you live in?\"].str.replace('united sates', 'USA')\n",
    "dfc[\"Which country do you live in?\"] = dfc[\"Which country do you live in?\"].str.replace('merica', 'USA')\n",
    "dfc[\"Which country do you live in?\"] = dfc[\"Which country do you live in?\"].str.replace('us', 'USA')\n",
    "dfc[\"Which country do you live in?\"] = dfc[\"Which country do you live in?\"].str.replace('usaa', 'USA')\n",
    "dfc[\"Which country do you live in?\"] = dfc[\"Which country do you live in?\"].str.replace('murica', 'USA')\n",
    "\n",
    "dfc[\"Which country do you live in?\"] = dfc[\"Which country do you live in?\"].str.replace('united kingdom', 'gbr')\n",
    "dfc[\"Which country do you live in?\"] = dfc[\"Which country do you live in?\"].str.replace('united kindom', 'gbr')\n",
    "dfc[\"Which country do you live in?\"] = dfc[\"Which country do you live in?\"].str.replace('england', 'gbr')\n",
    "\n",
    "dfc[\"Which country do you live in?\"] = dfc[\"Which country do you live in?\"].str.replace('japan', 'jpn')\n",
    "dfc[\"Which country do you live in?\"] = dfc[\"Which country do you live in?\"].str.replace('panama', 'pan')\n",
    "dfc[\"Which country do you live in?\"] = dfc[\"Which country do you live in?\"].str.replace('mexico', 'mex')\n",
    "dfc[\"Which country do you live in?\"] = dfc[\"Which country do you live in?\"].str.replace('france', 'fra')\n",
    "dfc[\"Which country do you live in?\"] = dfc[\"Which country do you live in?\"].str.replace('switzerland', 'che')\n",
    "dfc[\"Which country do you live in?\"] = dfc[\"Which country do you live in?\"].str.replace('belgium', 'bel')\n",
    "dfc[\"Which country do you live in?\"] = dfc[\"Which country do you live in?\"].str.replace('croatia', 'hrv')\n",
    "dfc[\"Which country do you live in?\"] = dfc[\"Which country do you live in?\"].str.replace('china', 'chn')\n",
    "\n",
    "dfc[\"Which country do you live in?\"] = dfc[\"Which country do you live in?\"].str.replace('germany', 'deu')\n",
    "dfc[\"Which country do you live in?\"] = dfc[\"Which country do you live in?\"].str.replace('philippines', 'phl')\n",
    "dfc[\"Which country do you live in?\"] = dfc[\"Which country do you live in?\"].str.replace('sweden', 'swe')\n",
    "dfc[\"Which country do you live in?\"] = dfc[\"Which country do you live in?\"].str.replace('finland', 'fin')\n",
    "dfc[\"Which country do you live in?\"] = dfc[\"Which country do you live in?\"].str.replace('kenya', 'ken')\n",
    "dfc[\"Which country do you live in?\"] = dfc[\"Which country do you live in?\"].str.replace('portugal', 'prt')\n",
    "dfc[\"Which country do you live in?\"] = dfc[\"Which country do you live in?\"].str.replace('brasil', 'bra')\n",
    "dfc[\"Which country do you live in?\"] = dfc[\"Which country do you live in?\"].str.replace('hungary', 'hun')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['can', 'USA', 'uk', 'jpn', 'fra',\n",
       "       'a tropical island south of the equator', 'gbr', 'che',\n",
       "       'neverland', 'this one', 'kr', '51', nan, 'bel', 'hrv', 'prt',\n",
       "       '47', 'cascadia', 'espaða', \"there isn't one for old men\", 'pan',\n",
       "       'one of the best ones', 'aUSAtralia', 'hun', 'aUSAtria',\n",
       "       'somewhere', 'nz', '54', 'deu', 'mex', '44', 'bra',\n",
       "       \"god's country\", 'phl', 'eua', '45', 'swe', 'nld', 'fin',\n",
       "       'trumpistan', 'chn', 'see above', 'ken', '30',\n",
       "       'the republic of cascadia', 'denial'], dtype=object)"
      ]
     },
     "execution_count": 1292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check of the previous lines of code using unique to easily find all unique values within column.\n",
    "\n",
    "dfc[\"Which country do you live in?\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1293,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here, I am just replacing a few left over strings which I did not see initially. The way that I knew \"espaöa\" meant \n",
    "#\"spain\" is because of four painful years of high school spanish which have now finally come of use. I replaced \n",
    "#all of these country names with their alpha-3 codes as usual.\n",
    "\n",
    "dfc[\"Which country do you live in?\"] = dfc[\"Which country do you live in?\"].str.replace('aUSAtralia', 'aus')\n",
    "dfc[\"Which country do you live in?\"] = dfc[\"Which country do you live in?\"].str.replace('aUSAtria', 'aut')\n",
    "dfc[\"Which country do you live in?\"] = dfc[\"Which country do you live in?\"].str.replace('espaða', 'esp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['can', 'USA', 'uk', 'jpn', 'fra', 'n/a', 'gbr', 'che', 'kr', '51',\n",
       "       nan, 'bel', 'hrv', 'prt', '47', 'esp', 'pan', 'aus', 'hun', 'aut',\n",
       "       'nz', '54', 'deu', 'mex', '44', 'bra', 'phl', '45', 'swe', 'nld',\n",
       "       'fin', 'chn', 'ken', '30'], dtype=object)"
      ]
     },
     "execution_count": 1294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Here, I am equating all string values with specific sub-strings (so that i dont have to type the whole string\n",
    "#when using the .replace function). I am basically taking the easy route and locating all string values with certain\n",
    "#short string sequences and then replacing the whole string with what the actual value should be. In this case, I chose\n",
    "#N/A since I don't want to remove the whole row of data and instead want to just show that that specific question \n",
    "#only did not get a satisfactory answer. \n",
    "\n",
    "dfc.loc[dfc['Which country do you live in?'].str.contains('tropical', na=False), 'Which country do you live in?'] = 'n/a'\n",
    "dfc.loc[dfc['Which country do you live in?'].str.contains('best', na=False), 'Which country do you live in?'] = 'n/a'\n",
    "dfc.loc[dfc['Which country do you live in?'].str.contains('somewhere', na=False), 'Which country do you live in?'] = 'n/a'\n",
    "dfc.loc[dfc['Which country do you live in?'].str.contains('cascadia', na=False), 'Which country do you live in?'] = 'n/a'\n",
    "dfc.loc[dfc['Which country do you live in?'].str.contains('eua', na=False), 'Which country do you live in?'] = 'n/a'\n",
    "dfc.loc[dfc['Which country do you live in?'].str.contains('see above', na=False), 'Which country do you live in?'] = 'n/a'\n",
    "dfc.loc[dfc['Which country do you live in?'].str.contains('neverland', na=False), 'Which country do you live in?'] = 'n/a'\n",
    "dfc.loc[dfc['Which country do you live in?'].str.contains('god', na=False), 'Which country do you live in?'] = 'n/a'\n",
    "dfc.loc[dfc['Which country do you live in?'].str.contains('men', na=False), 'Which country do you live in?'] = 'n/a'\n",
    "dfc.loc[dfc['Which country do you live in?'].str.contains('trumpistan', na=False), 'Which country do you live in?'] = 'n/a'\n",
    "dfc.loc[dfc['Which country do you live in?'].str.contains('denial', na=False), 'Which country do you live in?'] = 'n/a'\n",
    "dfc.loc[dfc['Which country do you live in?'].str.contains('this', na=False), 'Which country do you live in?'] = 'n/a'\n",
    "dfc.loc[dfc['Which country do you live in?'].str.contains('nan', na=False), 'Which country do you live in?'] = 'n/a'\n",
    "\n",
    "dfc['Which country do you live in?'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['can', 'USA', 'uk', 'jpn', 'fra', 'n/a', 'gbr', 'che', 'kr', nan,\n",
       "       'bel', 'hrv', 'prt', 'esp', 'pan', 'aus', 'hun', 'aut', 'nz',\n",
       "       'deu', 'mex', 'bra', 'phl', 'swe', 'nld', 'fin', 'chn', 'ken'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 1295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#From what is seen above, there are still some unneccessary numbers that I am unable to decipher in the context of\n",
    "#this column. I have elected to label them as 'N/A' instead of removing the whole row again. Unique to check that \n",
    "#the code has in fact functioned in the way intended. \n",
    "\n",
    "dfc.loc[dfc['Which country do you live in?'].str.contains('44', na=False), 'Which country do you live in?'] = 'n/a'\n",
    "dfc.loc[dfc['Which country do you live in?'].str.contains('47', na=False), 'Which country do you live in?'] = 'n/a'\n",
    "dfc.loc[dfc['Which country do you live in?'].str.contains('54', na=False), 'Which country do you live in?'] = 'n/a'\n",
    "dfc.loc[dfc['Which country do you live in?'].str.contains('45', na=False), 'Which country do you live in?'] = 'n/a'\n",
    "dfc.loc[dfc['Which country do you live in?'].str.contains('44', na=False), 'Which country do you live in?'] = 'n/a'\n",
    "dfc.loc[dfc['Which country do you live in?'].str.contains('30', na=False), 'Which country do you live in?'] = 'n/a'\n",
    "dfc.loc[dfc['Which country do you live in?'].str.contains('51', na=False), 'Which country do you live in?'] = 'n/a'\n",
    "\n",
    "dfc['Which country do you live in?'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CAN', 'USA', 'UK', 'JPN', 'FRA', 'N/A', 'GBR', 'CHE', 'KR', nan,\n",
       "       'BEL', 'HRV', 'PRT', 'ESP', 'PAN', 'AUS', 'HUN', 'AUT', 'NZ',\n",
       "       'DEU', 'MEX', 'BRA', 'PHL', 'SWE', 'NLD', 'FIN', 'CHN', 'KEN'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 1296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Here, i recapitalized things after I finished making the country names cleaner because that is traditionally how\n",
    "#alpha-3 is written. Using .uniue instead of info or head in order to check that I have correctly done everything.\n",
    "\n",
    "dfc[\"Which country do you live in?\"] = dfc[\"Which country do you live in?\"].str.upper()\n",
    "\n",
    "dfc['Which country do you live in?'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['22', '45', '48', '57', '42', '41', '47', '28', '44', '34', '46',\n",
       "       '40', '31', '33', '35', '49', '16', '60', '30', '51', '38', '54',\n",
       "       '43', '50', '37', '55', '58', '32', 'n/a', '64', '61', '65', '26',\n",
       "       '36', '78', '39', '52', '29', '63', '50s', nan, '10', '62', '23',\n",
       "       '20', '24', '17', '27', '53', '18', '13', '56', '66', '59', '25',\n",
       "       '74', '19', '14', '79', '50+', '70', '68', '81', '12', '67', '11',\n",
       "       '21', '71', '82', '15', '142', '7'], dtype=object)"
      ]
     },
     "execution_count": 1326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Here, I am cleaning up the age column for the candy dataframe. I am starting by using .unique so that I can see\n",
    "#what values we have in the dataframe and which ones I need to target. Here, there seen to be quite a few letters and\n",
    "#off values. \n",
    "\n",
    "dfc['How old are you?'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1327,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First, I am converting all letters to lowercase so that it is easier to target them since they will all be the same\n",
    "#case. \n",
    "\n",
    "dfc[\"How old are you?\"] = dfc[\"How old are you?\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['22', '45', '48', '57', '42', '41', '47', '28', '44', '34', '46',\n",
       "       '40', '31', '33', '35', '49', '16', '60', '30', '51', '38', '54',\n",
       "       '43', '50', '37', '55', '58', '32', 'n/a', '64', '61', '65', '26',\n",
       "       '36', '78', '39', '52', '29', '63', nan, '10', '62', '23', '20',\n",
       "       '24', '17', '27', '53', '18', '13', '56', '66', '59', '25', '74',\n",
       "       '19', '14', '79', '70', '68', '81', '12', '67', '11', '21', '71',\n",
       "       '82', '15', '142', '7'], dtype=object)"
      ]
     },
     "execution_count": 1328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Here, I am locating sub-strings in main strings and replacing the main strings with values like \"n/a\". For values that \n",
    "#say \"50+\" or \"55+\", I am simply turning them into the states values of \"50\" or \"55\" so that there will be no calcula\n",
    "#tion issues with this dataset if I leave in the pluses. They also did not specify a value above so, to stay safe I am \n",
    "#just stating the number already listed. Using .unique() at the end to check if my code worked. \n",
    "\n",
    "\n",
    "dfc.loc[dfc['How old are you?'].str.contains('old', na=False), 'How old are you?'] = 'n/a'\n",
    "dfc.loc[dfc['How old are you?'].str.contains('1.00E+18', na=False), 'How old are you?'] = 'n/a'\n",
    "dfc.loc[dfc['How old are you?'].str.contains('nixon', na=False), 'How old are you?'] = 'n/a'\n",
    "dfc.loc[dfc['How old are you?'].str.contains('woman', na=False), 'How old are you?'] = 'n/a'\n",
    "dfc.loc[dfc['How old are you?'].str.contains('haha', na=False), 'How old are you?'] = 'n/a'\n",
    "dfc.loc[dfc['How old are you?'].str.contains('ancient', na=False), 'How old are you?'] = 'n/a'\n",
    "dfc.loc[dfc['How old are you?'].str.contains('retirement', na=False), 'How old are you?'] = 'n/a'\n",
    "dfc.loc[dfc['How old are you?'].str.contains('mama', na=False), 'How old are you?'] = 'n/a'\n",
    "dfc.loc[dfc['How old are you?'].str.contains('1.00', na=False), 'How old are you?'] = 'n/a'\n",
    "dfc.loc[dfc['How old are you?'].str.contains('55+', na=False), 'How old are you?'] = '55'\n",
    "dfc.loc[dfc['How old are you?'].str.contains('50+', na=False), 'How old are you?'] = '50'\n",
    "\n",
    "dfc['How old are you?'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['22', '45', '48', '57', '42', '41', '47', '28', '44', '34', '46',\n",
       "       '40', '31', '33', '35', '49', '16', '60', '30', '51', '38', '54',\n",
       "       '43', '50', '37', '55', '58', '32', 'n/a', '64', '61', '65', '26',\n",
       "       '36', '78', '39', '52', '29', '63', nan, '10', '62', '23', '20',\n",
       "       '24', '17', '27', '53', '18', '13', '56', '66', '59', '25', '74',\n",
       "       '19', '14', '79', '70', '68', '81', '12', '67', '11', '21', '71',\n",
       "       '82', '15', '7'], dtype=object)"
      ]
     },
     "execution_count": 1330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Replacing letters with the number in number form and etc. Using replace since for these, contains() does not really \n",
    "#impact how easy writing the code is. For the value \"143\", I put n/a since that didn't make sense and, for \"over 40\",\n",
    "#I once again just stated the listed value to stay safe. Again used unique() to see if code worked. \n",
    "\n",
    "dfc[\"How old are you?\"] = dfc[\"How old are you?\"].str.replace('fifty.  nine.  ish.', '59')\n",
    "dfc[\"How old are you?\"] = dfc[\"How old are you?\"].str.replace('blah', 'n/a')\n",
    "dfc[\"How old are you?\"] = dfc[\"How old are you?\"].str.replace('49 11/12ths', '49')\n",
    "dfc[\"How old are you?\"] = dfc[\"How old are you?\"].str.replace('23.2', '23')\n",
    "dfc[\"How old are you?\"] = dfc[\"How old are you?\"].str.replace('0x2a', 'n/a')\n",
    "dfc[\"How old are you?\"] = dfc[\"How old are you?\"].str.replace(\"over 40\", '40')\n",
    "dfc[\"How old are you?\"] = dfc[\"How old are you?\"].str.replace('142', 'n/a')\n",
    "\n",
    "\n",
    "dfc['How old are you?'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Preparation 2 - Attendance Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Table 43. Average daily attendance (ADA) as a percentage of total enrollment, school day length, and school year length in public schools, by school level and state: 2007-08</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>Unnamed: 10</th>\n",
       "      <th>Unnamed: 11</th>\n",
       "      <th>Unnamed: 12</th>\n",
       "      <th>Unnamed: 13</th>\n",
       "      <th>Unnamed: 14</th>\n",
       "      <th>Unnamed: 15</th>\n",
       "      <th>Unnamed: 16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Total elementary, secondary, and combined elem...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Elementary schools</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Secondary schools</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ADA as percent of enrollment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Average hours in school day</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Average days in school year</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Average hours in school year</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ADA as percent of enrollment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Average hours in school day</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ADA as percent of enrollment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Average hours in school day</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>United States ........</td>\n",
       "      <td>93.1</td>\n",
       "      <td>(0.22)</td>\n",
       "      <td>6.6</td>\n",
       "      <td>(0.02)</td>\n",
       "      <td>180</td>\n",
       "      <td>(0.1)</td>\n",
       "      <td>1,193</td>\n",
       "      <td>(3.1)</td>\n",
       "      <td>94.0</td>\n",
       "      <td>(0.27)</td>\n",
       "      <td>6.7</td>\n",
       "      <td>(0.02)</td>\n",
       "      <td>91.1</td>\n",
       "      <td>(0.43)</td>\n",
       "      <td>6.6</td>\n",
       "      <td>(0.04)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alabama .................</td>\n",
       "      <td>93.8</td>\n",
       "      <td>(1.24)</td>\n",
       "      <td>7.0</td>\n",
       "      <td>(0.07)</td>\n",
       "      <td>180</td>\n",
       "      <td>(0.8)</td>\n",
       "      <td>1,267</td>\n",
       "      <td>(12.3)</td>\n",
       "      <td>93.8</td>\n",
       "      <td>(1.84)</td>\n",
       "      <td>7.0</td>\n",
       "      <td>(0.08)</td>\n",
       "      <td>94.6</td>\n",
       "      <td>(0.38)</td>\n",
       "      <td>7.1</td>\n",
       "      <td>(0.17)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Alaska ..................</td>\n",
       "      <td>89.9</td>\n",
       "      <td>(1.22)</td>\n",
       "      <td>6.5</td>\n",
       "      <td>(0.05)</td>\n",
       "      <td>180</td>\n",
       "      <td>(3.4)</td>\n",
       "      <td>1,163</td>\n",
       "      <td>(22.9)</td>\n",
       "      <td>91.3</td>\n",
       "      <td>(1.56)</td>\n",
       "      <td>6.5</td>\n",
       "      <td>(0.05)</td>\n",
       "      <td>93.2</td>\n",
       "      <td>(1.57)</td>\n",
       "      <td>6.2</td>\n",
       "      <td>(0.15)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Table 43. Average daily attendance (ADA) as a percentage of total enrollment, school day length, and school year length in public schools, by school level and state: 2007-08  \\\n",
       "0                                                NaN                                                                                                                              \n",
       "1                                                NaN                                                                                                                              \n",
       "2                                                  1                                                                                                                              \n",
       "3                             United States ........                                                                                                                              \n",
       "4                          Alabama .................                                                                                                                              \n",
       "5                          Alaska ..................                                                                                                                              \n",
       "\n",
       "                                          Unnamed: 1 Unnamed: 2  \\\n",
       "0  Total elementary, secondary, and combined elem...        NaN   \n",
       "1                       ADA as percent of enrollment        NaN   \n",
       "2                                                  2        NaN   \n",
       "3                                               93.1     (0.22)   \n",
       "4                                               93.8     (1.24)   \n",
       "5                                               89.9     (1.22)   \n",
       "\n",
       "                    Unnamed: 3 Unnamed: 4                   Unnamed: 5  \\\n",
       "0                          NaN        NaN                          NaN   \n",
       "1  Average hours in school day        NaN  Average days in school year   \n",
       "2                            3        NaN                            4   \n",
       "3                          6.6     (0.02)                          180   \n",
       "4                          7.0     (0.07)                          180   \n",
       "5                          6.5     (0.05)                          180   \n",
       "\n",
       "  Unnamed: 6                    Unnamed: 7 Unnamed: 8  \\\n",
       "0        NaN                           NaN        NaN   \n",
       "1        NaN  Average hours in school year        NaN   \n",
       "2        NaN                             5        NaN   \n",
       "3      (0.1)                         1,193      (3.1)   \n",
       "4      (0.8)                         1,267     (12.3)   \n",
       "5      (3.4)                         1,163     (22.9)   \n",
       "\n",
       "                     Unnamed: 9 Unnamed: 10                  Unnamed: 11  \\\n",
       "0            Elementary schools         NaN                          NaN   \n",
       "1  ADA as percent of enrollment         NaN  Average hours in school day   \n",
       "2                             6         NaN                            7   \n",
       "3                          94.0      (0.27)                          6.7   \n",
       "4                          93.8      (1.84)                          7.0   \n",
       "5                          91.3      (1.56)                          6.5   \n",
       "\n",
       "  Unnamed: 12                   Unnamed: 13 Unnamed: 14  \\\n",
       "0         NaN             Secondary schools         NaN   \n",
       "1         NaN  ADA as percent of enrollment         NaN   \n",
       "2         NaN                             8         NaN   \n",
       "3      (0.02)                          91.1      (0.43)   \n",
       "4      (0.08)                          94.6      (0.38)   \n",
       "5      (0.05)                          93.2      (1.57)   \n",
       "\n",
       "                   Unnamed: 15 Unnamed: 16  \n",
       "0                          NaN         NaN  \n",
       "1  Average hours in school day         NaN  \n",
       "2                            9         NaN  \n",
       "3                          6.6      (0.04)  \n",
       "4                          7.1      (0.17)  \n",
       "5                          6.2      (0.15)  "
      ]
     },
     "execution_count": 1306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Just printing first few values so I have an idea of what the dataset looks like and where the column names are located\n",
    "#because of the fact that I already know that none of the columns have names. \n",
    "\n",
    "dfa.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1307,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here, I am just renaming the first column because I can already tell that it is already by state and the current \n",
    "#title is much too long. Header starts at index 0 so that I can reference the column names.\n",
    "\n",
    "new_labels = ['State', 'Unnamed', 'Unnamed_2', 'Unnamed_3', 'Unnamed_4', 'Unnamed_5', 'Unnamed_6', 'Unnamed_7', 'Unnamed_8', 'Unnamed_9', 'Unnamed_10', 'Unnamed_11', 'Unnamed_12', 'Unnamed_13', 'Unnamed_14', 'Unnamed_15', 'Unnamed_16'] \n",
    "\n",
    "dfa = pd.read_csv(\"attendance.csv\", #name of csv file\n",
    "                 header=0,         #which indexed row in the file is the last header row this means rows 0..3 are headers\n",
    "                 names=new_labels, encoding=\"latin1\") #use the new_labels list for the column names. Notice there are no blanks\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Unnamed</th>\n",
       "      <th>Unnamed_2</th>\n",
       "      <th>Unnamed_3</th>\n",
       "      <th>Unnamed_4</th>\n",
       "      <th>Unnamed_5</th>\n",
       "      <th>Unnamed_6</th>\n",
       "      <th>Unnamed_7</th>\n",
       "      <th>Unnamed_8</th>\n",
       "      <th>Unnamed_9</th>\n",
       "      <th>Unnamed_10</th>\n",
       "      <th>Unnamed_11</th>\n",
       "      <th>Unnamed_12</th>\n",
       "      <th>Unnamed_13</th>\n",
       "      <th>Unnamed_14</th>\n",
       "      <th>Unnamed_15</th>\n",
       "      <th>Unnamed_16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Wyoming .................</td>\n",
       "      <td>92.4</td>\n",
       "      <td>(1.15)</td>\n",
       "      <td>6.9</td>\n",
       "      <td>(0.05)</td>\n",
       "      <td>175</td>\n",
       "      <td>(1.3)</td>\n",
       "      <td>1,201</td>\n",
       "      <td>(8.3)</td>\n",
       "      <td>92.2</td>\n",
       "      <td>(1.65)</td>\n",
       "      <td>6.9</td>\n",
       "      <td>(0.05)</td>\n",
       "      <td>92.4</td>\n",
       "      <td>(0.75)</td>\n",
       "      <td>7.0</td>\n",
       "      <td>(0.07)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Not applicable.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>àReporting standards not met (too few cases).</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>NOTE: Averages reflect data reported by school...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>SOURCE: U.S. Department of Education, National...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                State Unnamed Unnamed_2  \\\n",
       "63                          Wyoming .................    92.4    (1.15)   \n",
       "64                                    Not applicable.     NaN       NaN   \n",
       "65    àReporting standards not met (too few cases).       NaN       NaN   \n",
       "66  NOTE: Averages reflect data reported by school...     NaN       NaN   \n",
       "67  SOURCE: U.S. Department of Education, National...     NaN       NaN   \n",
       "\n",
       "   Unnamed_3 Unnamed_4 Unnamed_5 Unnamed_6 Unnamed_7 Unnamed_8 Unnamed_9  \\\n",
       "63       6.9    (0.05)       175     (1.3)     1,201     (8.3)      92.2   \n",
       "64       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "65       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "66       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "67       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "   Unnamed_10 Unnamed_11 Unnamed_12 Unnamed_13 Unnamed_14 Unnamed_15  \\\n",
       "63     (1.65)        6.9     (0.05)       92.4     (0.75)        7.0   \n",
       "64        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "65        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "66        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "67        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "\n",
       "   Unnamed_16  \n",
       "63     (0.07)  \n",
       "64        NaN  \n",
       "65        NaN  \n",
       "66        NaN  \n",
       "67        NaN  "
      ]
     },
     "execution_count": 1308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Looking at last few values to see if anything there will help me name the columns any further and to see if there is \n",
    "#anything I need to clean. From this, I can probably remove all of index[64]. There are also a few notes so we can \n",
    "#locate these inputs to help learn more about this data. \n",
    "\n",
    "dfa.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NOTE: Averages reflect data reported by schools rather than state requirements. School-reported length of day may exceed state requirements, and there is a range of statistical error in reported estimates. Standard errors appear in parentheses. '"
      ]
     },
     "execution_count": 1309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Here, i am targeting one of the notes because I feel that it may be of use to me in deciphering the data. Seeing\n",
    "#the full note makes me realize that the decimal data values (which appear in paretheses) are apparently Standard Error\n",
    "#values. This helps me name the columns with no name hint.\n",
    "\n",
    "dfa.loc[66,'State']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1310,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here, based on the labels (which are placed in the wrong row), I am renaming the columns. Based on the note I just \n",
    "#saw, i now know what the decimal values mean (Standard error) and am naming them accordingly. I am also grouping\n",
    "#the columns based on a) Secondary & Elementary (Total) values b) Elementary School Data or c) Secondary School Values.\n",
    "#I am having header = 3 since row with index 3 is the row where actual data starts. The ones before are a mix of \n",
    "#NaNs and header names which I will no longer need after I rename the columns. \n",
    "\n",
    "new_labels = ['State', 'Total_ADA_Percentage', 'Total_Standard_Error_ADA', 'Total_Avg_School_Day_Hrs', 'Standard_Error_Total_Hrs/Day', 'Total_Avg_School_Days_Year', 'Standard_Error_Total_Days/Year', 'Total_Avg_School_Total_Hrs/Year', 'Standard_Error_Total_Hrs/Year', 'Elementary_ADA_Percentage', 'Elementary_Standard_Error_AD', 'Elementary_Avg_School_Day_Hrs', 'Standard_Error_Elementary_Hrs/Day', 'Secondary_ADA_Percentage', 'Secondary_Standard_Error_ADA', 'Secondary_Avg_School_Day_Hrs', 'Standard_Error_Secondary_Hrs/Day'] \n",
    "\n",
    "dfa = pd.read_csv(\"attendance.csv\", #name of csv file\n",
    "                 header=3,         #which indexed row in the file is the last header row this means rows 0..3 are headers\n",
    "                 names=new_labels, encoding=\"latin1\") #use the new_labels list for the column names. Notice there are\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Total_ADA_Percentage</th>\n",
       "      <th>Total_Standard_Error_ADA</th>\n",
       "      <th>Total_Avg_School_Day_Hrs</th>\n",
       "      <th>Standard_Error_Total_Hrs/Day</th>\n",
       "      <th>Total_Avg_School_Days_Year</th>\n",
       "      <th>Standard_Error_Total_Days/Year</th>\n",
       "      <th>Total_Avg_School_Total_Hrs/Year</th>\n",
       "      <th>Standard_Error_Total_Hrs/Year</th>\n",
       "      <th>Elementary_ADA_Percentage</th>\n",
       "      <th>Elementary_Standard_Error_AD</th>\n",
       "      <th>Elementary_Avg_School_Day_Hrs</th>\n",
       "      <th>Standard_Error_Elementary_Hrs/Day</th>\n",
       "      <th>Secondary_ADA_Percentage</th>\n",
       "      <th>Secondary_Standard_Error_ADA</th>\n",
       "      <th>Secondary_Avg_School_Day_Hrs</th>\n",
       "      <th>Standard_Error_Secondary_Hrs/Day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>United States ........</td>\n",
       "      <td>93.1</td>\n",
       "      <td>(0.22)</td>\n",
       "      <td>6.6</td>\n",
       "      <td>(0.02)</td>\n",
       "      <td>180.0</td>\n",
       "      <td>(0.1)</td>\n",
       "      <td>1,193</td>\n",
       "      <td>(3.1)</td>\n",
       "      <td>94.0</td>\n",
       "      <td>(0.27)</td>\n",
       "      <td>6.7</td>\n",
       "      <td>(0.02)</td>\n",
       "      <td>91.1</td>\n",
       "      <td>(0.43)</td>\n",
       "      <td>6.6</td>\n",
       "      <td>(0.04)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alabama .................</td>\n",
       "      <td>93.8</td>\n",
       "      <td>(1.24)</td>\n",
       "      <td>7.0</td>\n",
       "      <td>(0.07)</td>\n",
       "      <td>180.0</td>\n",
       "      <td>(0.8)</td>\n",
       "      <td>1,267</td>\n",
       "      <td>(12.3)</td>\n",
       "      <td>93.8</td>\n",
       "      <td>(1.84)</td>\n",
       "      <td>7.0</td>\n",
       "      <td>(0.08)</td>\n",
       "      <td>94.6</td>\n",
       "      <td>(0.38)</td>\n",
       "      <td>7.1</td>\n",
       "      <td>(0.17)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alaska ..................</td>\n",
       "      <td>89.9</td>\n",
       "      <td>(1.22)</td>\n",
       "      <td>6.5</td>\n",
       "      <td>(0.05)</td>\n",
       "      <td>180.0</td>\n",
       "      <td>(3.4)</td>\n",
       "      <td>1,163</td>\n",
       "      <td>(22.9)</td>\n",
       "      <td>91.3</td>\n",
       "      <td>(1.56)</td>\n",
       "      <td>6.5</td>\n",
       "      <td>(0.05)</td>\n",
       "      <td>93.2</td>\n",
       "      <td>(1.57)</td>\n",
       "      <td>6.2</td>\n",
       "      <td>(0.15)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arizona .................</td>\n",
       "      <td>89.0</td>\n",
       "      <td>(2.95)</td>\n",
       "      <td>6.4</td>\n",
       "      <td>(0.09)</td>\n",
       "      <td>181.0</td>\n",
       "      <td>(1.7)</td>\n",
       "      <td>1,159</td>\n",
       "      <td>(14.4)</td>\n",
       "      <td>88.9</td>\n",
       "      <td>(3.91)</td>\n",
       "      <td>6.4</td>\n",
       "      <td>(0.10)</td>\n",
       "      <td>89.0</td>\n",
       "      <td>(3.22)</td>\n",
       "      <td>6.4</td>\n",
       "      <td>(0.25)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arkansas ................</td>\n",
       "      <td>91.8</td>\n",
       "      <td>(1.35)</td>\n",
       "      <td>6.9</td>\n",
       "      <td>(0.06)</td>\n",
       "      <td>179.0</td>\n",
       "      <td>(0.2)</td>\n",
       "      <td>1,229</td>\n",
       "      <td>(10.7)</td>\n",
       "      <td>92.1</td>\n",
       "      <td>(2.09)</td>\n",
       "      <td>6.9</td>\n",
       "      <td>(0.08)</td>\n",
       "      <td>90.8</td>\n",
       "      <td>(2.23)</td>\n",
       "      <td>6.8</td>\n",
       "      <td>(0.10)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>California ..............</td>\n",
       "      <td>93.2</td>\n",
       "      <td>(0.71)</td>\n",
       "      <td>6.2</td>\n",
       "      <td>(0.07)</td>\n",
       "      <td>181.0</td>\n",
       "      <td>(0.4)</td>\n",
       "      <td>1,129</td>\n",
       "      <td>(12.5)</td>\n",
       "      <td>94.9</td>\n",
       "      <td>(0.75)</td>\n",
       "      <td>6.3</td>\n",
       "      <td>(0.05)</td>\n",
       "      <td>89.4</td>\n",
       "      <td>(1.45)</td>\n",
       "      <td>6.1</td>\n",
       "      <td>(0.20)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Colorado ................</td>\n",
       "      <td>93.9</td>\n",
       "      <td>(0.44)</td>\n",
       "      <td>7.0</td>\n",
       "      <td>(0.05)</td>\n",
       "      <td>171.0</td>\n",
       "      <td>(1.0)</td>\n",
       "      <td>1,199</td>\n",
       "      <td>(9.9)</td>\n",
       "      <td>94.5</td>\n",
       "      <td>(0.45)</td>\n",
       "      <td>7.0</td>\n",
       "      <td>(0.07)</td>\n",
       "      <td>91.2</td>\n",
       "      <td>(1.28)</td>\n",
       "      <td>7.0</td>\n",
       "      <td>(0.11)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Connecticut .............</td>\n",
       "      <td>87.9</td>\n",
       "      <td>(2.98)</td>\n",
       "      <td>6.5</td>\n",
       "      <td>(0.09)</td>\n",
       "      <td>181.0</td>\n",
       "      <td>(0.1)</td>\n",
       "      <td>1,173</td>\n",
       "      <td>(15.9)</td>\n",
       "      <td>87.4</td>\n",
       "      <td>(3.98)</td>\n",
       "      <td>6.5</td>\n",
       "      <td>(0.11)</td>\n",
       "      <td>93.7</td>\n",
       "      <td>(0.68)</td>\n",
       "      <td>6.5</td>\n",
       "      <td>(0.09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Delaware ................</td>\n",
       "      <td>89.8</td>\n",
       "      <td>(1.75)</td>\n",
       "      <td>6.7</td>\n",
       "      <td>(0.09)</td>\n",
       "      <td>181.0</td>\n",
       "      <td>(0.8)</td>\n",
       "      <td>1,208</td>\n",
       "      <td>(18.7)</td>\n",
       "      <td>89.4</td>\n",
       "      <td>(2.50)</td>\n",
       "      <td>6.8</td>\n",
       "      <td>(0.06)</td>\n",
       "      <td>à</td>\n",
       "      <td>( )</td>\n",
       "      <td>6.5</td>\n",
       "      <td>(0.23)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>District of Columbia ....</td>\n",
       "      <td>91.2</td>\n",
       "      <td>(1.27)</td>\n",
       "      <td>6.9</td>\n",
       "      <td>(0.21)</td>\n",
       "      <td>181.0</td>\n",
       "      <td>(0.4)</td>\n",
       "      <td>1,256</td>\n",
       "      <td>(42.3)</td>\n",
       "      <td>93.9</td>\n",
       "      <td>(0.38)</td>\n",
       "      <td>6.9</td>\n",
       "      <td>(0.10)</td>\n",
       "      <td>à</td>\n",
       "      <td>( )</td>\n",
       "      <td>à</td>\n",
       "      <td>( )</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Florida .................</td>\n",
       "      <td>92.7</td>\n",
       "      <td>(0.74)</td>\n",
       "      <td>6.4</td>\n",
       "      <td>(0.08)</td>\n",
       "      <td>184.0</td>\n",
       "      <td>(1.2)</td>\n",
       "      <td>1,184</td>\n",
       "      <td>(18.8)</td>\n",
       "      <td>94.0</td>\n",
       "      <td>(0.94)</td>\n",
       "      <td>6.5</td>\n",
       "      <td>(0.05)</td>\n",
       "      <td>89.9</td>\n",
       "      <td>(1.43)</td>\n",
       "      <td>6.3</td>\n",
       "      <td>(0.38)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Georgia .................</td>\n",
       "      <td>93.3</td>\n",
       "      <td>(1.28)</td>\n",
       "      <td>6.8</td>\n",
       "      <td>(0.06)</td>\n",
       "      <td>181.0</td>\n",
       "      <td>(1.0)</td>\n",
       "      <td>1,229</td>\n",
       "      <td>(12.4)</td>\n",
       "      <td>93.9</td>\n",
       "      <td>(1.60)</td>\n",
       "      <td>6.8</td>\n",
       "      <td>(0.06)</td>\n",
       "      <td>93.1</td>\n",
       "      <td>(1.23)</td>\n",
       "      <td>6.9</td>\n",
       "      <td>(0.09)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Hawaii ..................</td>\n",
       "      <td>90.7</td>\n",
       "      <td>(4.58)</td>\n",
       "      <td>6.3</td>\n",
       "      <td>(0.10)</td>\n",
       "      <td>179.0</td>\n",
       "      <td>(1.6)</td>\n",
       "      <td>1,118</td>\n",
       "      <td>(12.7)</td>\n",
       "      <td>90.8</td>\n",
       "      <td>(2.63)</td>\n",
       "      <td>6.2</td>\n",
       "      <td>(0.05)</td>\n",
       "      <td>à</td>\n",
       "      <td>( )</td>\n",
       "      <td>à</td>\n",
       "      <td>( )</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        State  Total_ADA_Percentage Total_Standard_Error_ADA  \\\n",
       "0      United States ........                  93.1                   (0.22)   \n",
       "1   Alabama .................                  93.8                   (1.24)   \n",
       "2   Alaska ..................                  89.9                   (1.22)   \n",
       "3   Arizona .................                  89.0                   (2.95)   \n",
       "4   Arkansas ................                  91.8                   (1.35)   \n",
       "5   California ..............                  93.2                   (0.71)   \n",
       "6                         NaN                   NaN                      NaN   \n",
       "7   Colorado ................                  93.9                   (0.44)   \n",
       "8   Connecticut .............                  87.9                   (2.98)   \n",
       "9   Delaware ................                  89.8                   (1.75)   \n",
       "10  District of Columbia ....                  91.2                   (1.27)   \n",
       "11  Florida .................                  92.7                   (0.74)   \n",
       "12                        NaN                   NaN                      NaN   \n",
       "13  Georgia .................                  93.3                   (1.28)   \n",
       "14  Hawaii ..................                  90.7                   (4.58)   \n",
       "\n",
       "    Total_Avg_School_Day_Hrs Standard_Error_Total_Hrs/Day  \\\n",
       "0                        6.6                       (0.02)   \n",
       "1                        7.0                       (0.07)   \n",
       "2                        6.5                       (0.05)   \n",
       "3                        6.4                       (0.09)   \n",
       "4                        6.9                       (0.06)   \n",
       "5                        6.2                       (0.07)   \n",
       "6                        NaN                          NaN   \n",
       "7                        7.0                       (0.05)   \n",
       "8                        6.5                       (0.09)   \n",
       "9                        6.7                       (0.09)   \n",
       "10                       6.9                       (0.21)   \n",
       "11                       6.4                       (0.08)   \n",
       "12                       NaN                          NaN   \n",
       "13                       6.8                       (0.06)   \n",
       "14                       6.3                       (0.10)   \n",
       "\n",
       "    Total_Avg_School_Days_Year Standard_Error_Total_Days/Year  \\\n",
       "0                        180.0                          (0.1)   \n",
       "1                        180.0                          (0.8)   \n",
       "2                        180.0                          (3.4)   \n",
       "3                        181.0                          (1.7)   \n",
       "4                        179.0                          (0.2)   \n",
       "5                        181.0                          (0.4)   \n",
       "6                          NaN                            NaN   \n",
       "7                        171.0                          (1.0)   \n",
       "8                        181.0                          (0.1)   \n",
       "9                        181.0                          (0.8)   \n",
       "10                       181.0                          (0.4)   \n",
       "11                       184.0                          (1.2)   \n",
       "12                         NaN                            NaN   \n",
       "13                       181.0                          (1.0)   \n",
       "14                       179.0                          (1.6)   \n",
       "\n",
       "   Total_Avg_School_Total_Hrs/Year Standard_Error_Total_Hrs/Year  \\\n",
       "0                            1,193                         (3.1)   \n",
       "1                            1,267                        (12.3)   \n",
       "2                            1,163                        (22.9)   \n",
       "3                            1,159                        (14.4)   \n",
       "4                            1,229                        (10.7)   \n",
       "5                            1,129                        (12.5)   \n",
       "6                              NaN                           NaN   \n",
       "7                            1,199                         (9.9)   \n",
       "8                            1,173                        (15.9)   \n",
       "9                            1,208                        (18.7)   \n",
       "10                           1,256                        (42.3)   \n",
       "11                           1,184                        (18.8)   \n",
       "12                             NaN                           NaN   \n",
       "13                           1,229                        (12.4)   \n",
       "14                           1,118                        (12.7)   \n",
       "\n",
       "    Elementary_ADA_Percentage Elementary_Standard_Error_AD  \\\n",
       "0                        94.0                       (0.27)   \n",
       "1                        93.8                       (1.84)   \n",
       "2                        91.3                       (1.56)   \n",
       "3                        88.9                       (3.91)   \n",
       "4                        92.1                       (2.09)   \n",
       "5                        94.9                       (0.75)   \n",
       "6                         NaN                          NaN   \n",
       "7                        94.5                       (0.45)   \n",
       "8                        87.4                       (3.98)   \n",
       "9                        89.4                       (2.50)   \n",
       "10                       93.9                       (0.38)   \n",
       "11                       94.0                       (0.94)   \n",
       "12                        NaN                          NaN   \n",
       "13                       93.9                       (1.60)   \n",
       "14                       90.8                       (2.63)   \n",
       "\n",
       "    Elementary_Avg_School_Day_Hrs Standard_Error_Elementary_Hrs/Day  \\\n",
       "0                             6.7                            (0.02)   \n",
       "1                             7.0                            (0.08)   \n",
       "2                             6.5                            (0.05)   \n",
       "3                             6.4                            (0.10)   \n",
       "4                             6.9                            (0.08)   \n",
       "5                             6.3                            (0.05)   \n",
       "6                             NaN                               NaN   \n",
       "7                             7.0                            (0.07)   \n",
       "8                             6.5                            (0.11)   \n",
       "9                             6.8                            (0.06)   \n",
       "10                            6.9                            (0.10)   \n",
       "11                            6.5                            (0.05)   \n",
       "12                            NaN                               NaN   \n",
       "13                            6.8                            (0.06)   \n",
       "14                            6.2                            (0.05)   \n",
       "\n",
       "   Secondary_ADA_Percentage Secondary_Standard_Error_ADA  \\\n",
       "0                      91.1                       (0.43)   \n",
       "1                      94.6                       (0.38)   \n",
       "2                      93.2                       (1.57)   \n",
       "3                      89.0                       (3.22)   \n",
       "4                      90.8                       (2.23)   \n",
       "5                      89.4                       (1.45)   \n",
       "6                       NaN                          NaN   \n",
       "7                      91.2                       (1.28)   \n",
       "8                      93.7                       (0.68)   \n",
       "9                         à                          ( )   \n",
       "10                        à                          ( )   \n",
       "11                     89.9                       (1.43)   \n",
       "12                      NaN                          NaN   \n",
       "13                     93.1                       (1.23)   \n",
       "14                        à                          ( )   \n",
       "\n",
       "   Secondary_Avg_School_Day_Hrs Standard_Error_Secondary_Hrs/Day  \n",
       "0                           6.6                           (0.04)  \n",
       "1                           7.1                           (0.17)  \n",
       "2                           6.2                           (0.15)  \n",
       "3                           6.4                           (0.25)  \n",
       "4                           6.8                           (0.10)  \n",
       "5                           6.1                           (0.20)  \n",
       "6                           NaN                              NaN  \n",
       "7                           7.0                           (0.11)  \n",
       "8                           6.5                           (0.09)  \n",
       "9                           6.5                           (0.23)  \n",
       "10                            à                              ( )  \n",
       "11                          6.3                           (0.38)  \n",
       "12                          NaN                              NaN  \n",
       "13                          6.9                           (0.09)  \n",
       "14                            à                              ( )  "
      ]
     },
     "execution_count": 1311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking first few rows to make sure there are no problems after my last line of code. I use 15 as my # of rows just\n",
    "#so I get a larger sample size than just 5. This is where I notice that there are full rows where the values are just \n",
    "#NaNs. This is a problem I will soon fix.\n",
    "\n",
    "dfa.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1312,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here, I am dropping all rows which contain only NaNs. I noticed that there were certain rows with this problem (such \n",
    "#as row index 6) and this is an easy solution to the ocassional row breaks.\n",
    "dfa.dropna(how='all', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1313,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here, based on the note in tails which stated that \"à\" meant that \"Reporting standards weren't met\", I am now\n",
    "#replacing all \"à\" synbols with an appropriate message. After looking through examples of the \"à\" variable in the set,\n",
    "#I have noticed that the presence of the \"à\" means that the Standard Error is also blank so, I have left the same mes-\n",
    "#sage for the empty parenthesis too.\n",
    "\n",
    "dfa = dfa.replace('à', 'ReportingStandardsNotMet')\n",
    "dfa = dfa.replace('(\\xa0)', 'ReportingStandardsNotMet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ReportingStandardsNotMet'"
      ]
     },
     "execution_count": 1314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#here, I am targeting a specific row which I know has the values I have just replaced. By locatng and printing\n",
    "#the values, I am able to learn if my code has actually worked and has replaced the necessary values with \n",
    "#'ReportingStandardsNotMet'. Here, we can see that it has worked which means that it should work with every other \n",
    "#value of \"à\" in the dataframe.\n",
    "\n",
    "dfa.loc[9, 'Secondary_ADA_Percentage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ReportingStandardsNotMet'"
      ]
     },
     "execution_count": 1315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Again, checking previous line of code to make sure that empty parentheses have now been replaced. \n",
    "dfa.loc[9, 'Secondary_Standard_Error_ADA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Total_ADA_Percentage</th>\n",
       "      <th>Total_Standard_Error_ADA</th>\n",
       "      <th>Total_Avg_School_Day_Hrs</th>\n",
       "      <th>Standard_Error_Total_Hrs/Day</th>\n",
       "      <th>Total_Avg_School_Days_Year</th>\n",
       "      <th>Standard_Error_Total_Days/Year</th>\n",
       "      <th>Total_Avg_School_Total_Hrs/Year</th>\n",
       "      <th>Standard_Error_Total_Hrs/Year</th>\n",
       "      <th>Elementary_ADA_Percentage</th>\n",
       "      <th>Elementary_Standard_Error_AD</th>\n",
       "      <th>Elementary_Avg_School_Day_Hrs</th>\n",
       "      <th>Standard_Error_Elementary_Hrs/Day</th>\n",
       "      <th>Secondary_ADA_Percentage</th>\n",
       "      <th>Secondary_Standard_Error_ADA</th>\n",
       "      <th>Secondary_Avg_School_Day_Hrs</th>\n",
       "      <th>Standard_Error_Secondary_Hrs/Day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Wyoming .................</td>\n",
       "      <td>92.4</td>\n",
       "      <td>(1.15)</td>\n",
       "      <td>6.9</td>\n",
       "      <td>(0.05)</td>\n",
       "      <td>175.0</td>\n",
       "      <td>(1.3)</td>\n",
       "      <td>1,201</td>\n",
       "      <td>(8.3)</td>\n",
       "      <td>92.2</td>\n",
       "      <td>(1.65)</td>\n",
       "      <td>6.9</td>\n",
       "      <td>(0.05)</td>\n",
       "      <td>92.4</td>\n",
       "      <td>(0.75)</td>\n",
       "      <td>7.0</td>\n",
       "      <td>(0.07)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Not applicable.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>àReporting standards not met (too few cases).</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>NOTE: Averages reflect data reported by school...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>SOURCE: U.S. Department of Education, National...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                State  Total_ADA_Percentage  \\\n",
       "60                          Wyoming .................                  92.4   \n",
       "61                                    Not applicable.                   NaN   \n",
       "62    àReporting standards not met (too few cases).                     NaN   \n",
       "63  NOTE: Averages reflect data reported by school...                   NaN   \n",
       "64  SOURCE: U.S. Department of Education, National...                   NaN   \n",
       "\n",
       "   Total_Standard_Error_ADA  Total_Avg_School_Day_Hrs  \\\n",
       "60                   (1.15)                       6.9   \n",
       "61                      NaN                       NaN   \n",
       "62                      NaN                       NaN   \n",
       "63                      NaN                       NaN   \n",
       "64                      NaN                       NaN   \n",
       "\n",
       "   Standard_Error_Total_Hrs/Day  Total_Avg_School_Days_Year  \\\n",
       "60                       (0.05)                       175.0   \n",
       "61                          NaN                         NaN   \n",
       "62                          NaN                         NaN   \n",
       "63                          NaN                         NaN   \n",
       "64                          NaN                         NaN   \n",
       "\n",
       "   Standard_Error_Total_Days/Year Total_Avg_School_Total_Hrs/Year  \\\n",
       "60                          (1.3)                           1,201   \n",
       "61                            NaN                             NaN   \n",
       "62                            NaN                             NaN   \n",
       "63                            NaN                             NaN   \n",
       "64                            NaN                             NaN   \n",
       "\n",
       "   Standard_Error_Total_Hrs/Year  Elementary_ADA_Percentage  \\\n",
       "60                         (8.3)                       92.2   \n",
       "61                           NaN                        NaN   \n",
       "62                           NaN                        NaN   \n",
       "63                           NaN                        NaN   \n",
       "64                           NaN                        NaN   \n",
       "\n",
       "   Elementary_Standard_Error_AD  Elementary_Avg_School_Day_Hrs  \\\n",
       "60                       (1.65)                            6.9   \n",
       "61                          NaN                            NaN   \n",
       "62                          NaN                            NaN   \n",
       "63                          NaN                            NaN   \n",
       "64                          NaN                            NaN   \n",
       "\n",
       "   Standard_Error_Elementary_Hrs/Day Secondary_ADA_Percentage  \\\n",
       "60                            (0.05)                     92.4   \n",
       "61                               NaN                      NaN   \n",
       "62                               NaN                      NaN   \n",
       "63                               NaN                      NaN   \n",
       "64                               NaN                      NaN   \n",
       "\n",
       "   Secondary_Standard_Error_ADA Secondary_Avg_School_Day_Hrs  \\\n",
       "60                       (0.75)                          7.0   \n",
       "61                          NaN                          NaN   \n",
       "62                          NaN                          NaN   \n",
       "63                          NaN                          NaN   \n",
       "64                          NaN                          NaN   \n",
       "\n",
       "   Standard_Error_Secondary_Hrs/Day  \n",
       "60                           (0.07)  \n",
       "61                              NaN  \n",
       "62                              NaN  \n",
       "63                              NaN  \n",
       "64                              NaN  "
      ]
     },
     "execution_count": 1316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking data just to see if any other changes need to be made in the notes.\n",
    "dfa.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1317,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here, I am removing the note which says \"not applicable\" because I see no use for this line. I do not learn any \n",
    "#new information and I don't believe that i need it. Also removed line which said \"à\" meant Reporting Standards not\n",
    "#met because I already replaced all \"à\"'s from the Dataframe'. However, I left the other notes because I think that \n",
    "#they are important in order to understand/interpret the data and, the source is useful to give the data credibility. \n",
    "\n",
    "dfa.drop([61, 62], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Total_ADA_Percentage</th>\n",
       "      <th>Total_Standard_Error_ADA</th>\n",
       "      <th>Total_Avg_School_Day_Hrs</th>\n",
       "      <th>Standard_Error_Total_Hrs/Day</th>\n",
       "      <th>Total_Avg_School_Days_Year</th>\n",
       "      <th>Standard_Error_Total_Days/Year</th>\n",
       "      <th>Total_Avg_School_Total_Hrs/Year</th>\n",
       "      <th>Standard_Error_Total_Hrs/Year</th>\n",
       "      <th>Elementary_ADA_Percentage</th>\n",
       "      <th>Elementary_Standard_Error_AD</th>\n",
       "      <th>Elementary_Avg_School_Day_Hrs</th>\n",
       "      <th>Standard_Error_Elementary_Hrs/Day</th>\n",
       "      <th>Secondary_ADA_Percentage</th>\n",
       "      <th>Secondary_Standard_Error_ADA</th>\n",
       "      <th>Secondary_Avg_School_Day_Hrs</th>\n",
       "      <th>Standard_Error_Secondary_Hrs/Day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>West Virginia ...........</td>\n",
       "      <td>94.0</td>\n",
       "      <td>(0.99)</td>\n",
       "      <td>6.9</td>\n",
       "      <td>(0.07)</td>\n",
       "      <td>182.0</td>\n",
       "      <td>(0.5)</td>\n",
       "      <td>1,251</td>\n",
       "      <td>(13.7)</td>\n",
       "      <td>94.4</td>\n",
       "      <td>(1.32)</td>\n",
       "      <td>6.9</td>\n",
       "      <td>(0.09)</td>\n",
       "      <td>92.8</td>\n",
       "      <td>(0.41)</td>\n",
       "      <td>6.8</td>\n",
       "      <td>(0.14)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Wisconsin ...............</td>\n",
       "      <td>95.0</td>\n",
       "      <td>(0.57)</td>\n",
       "      <td>6.9</td>\n",
       "      <td>(0.04)</td>\n",
       "      <td>180.0</td>\n",
       "      <td>(0.7)</td>\n",
       "      <td>1,246</td>\n",
       "      <td>(8.6)</td>\n",
       "      <td>95.4</td>\n",
       "      <td>(0.41)</td>\n",
       "      <td>6.9</td>\n",
       "      <td>(0.05)</td>\n",
       "      <td>93.0</td>\n",
       "      <td>(1.91)</td>\n",
       "      <td>7.0</td>\n",
       "      <td>(0.14)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Wyoming .................</td>\n",
       "      <td>92.4</td>\n",
       "      <td>(1.15)</td>\n",
       "      <td>6.9</td>\n",
       "      <td>(0.05)</td>\n",
       "      <td>175.0</td>\n",
       "      <td>(1.3)</td>\n",
       "      <td>1,201</td>\n",
       "      <td>(8.3)</td>\n",
       "      <td>92.2</td>\n",
       "      <td>(1.65)</td>\n",
       "      <td>6.9</td>\n",
       "      <td>(0.05)</td>\n",
       "      <td>92.4</td>\n",
       "      <td>(0.75)</td>\n",
       "      <td>7.0</td>\n",
       "      <td>(0.07)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>NOTE: Averages reflect data reported by school...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>SOURCE: U.S. Department of Education, National...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                State  Total_ADA_Percentage  \\\n",
       "58                          West Virginia ...........                  94.0   \n",
       "59                          Wisconsin ...............                  95.0   \n",
       "60                          Wyoming .................                  92.4   \n",
       "63  NOTE: Averages reflect data reported by school...                   NaN   \n",
       "64  SOURCE: U.S. Department of Education, National...                   NaN   \n",
       "\n",
       "   Total_Standard_Error_ADA  Total_Avg_School_Day_Hrs  \\\n",
       "58                   (0.99)                       6.9   \n",
       "59                   (0.57)                       6.9   \n",
       "60                   (1.15)                       6.9   \n",
       "63                      NaN                       NaN   \n",
       "64                      NaN                       NaN   \n",
       "\n",
       "   Standard_Error_Total_Hrs/Day  Total_Avg_School_Days_Year  \\\n",
       "58                       (0.07)                       182.0   \n",
       "59                       (0.04)                       180.0   \n",
       "60                       (0.05)                       175.0   \n",
       "63                          NaN                         NaN   \n",
       "64                          NaN                         NaN   \n",
       "\n",
       "   Standard_Error_Total_Days/Year Total_Avg_School_Total_Hrs/Year  \\\n",
       "58                          (0.5)                           1,251   \n",
       "59                          (0.7)                           1,246   \n",
       "60                          (1.3)                           1,201   \n",
       "63                            NaN                             NaN   \n",
       "64                            NaN                             NaN   \n",
       "\n",
       "   Standard_Error_Total_Hrs/Year  Elementary_ADA_Percentage  \\\n",
       "58                        (13.7)                       94.4   \n",
       "59                         (8.6)                       95.4   \n",
       "60                         (8.3)                       92.2   \n",
       "63                           NaN                        NaN   \n",
       "64                           NaN                        NaN   \n",
       "\n",
       "   Elementary_Standard_Error_AD  Elementary_Avg_School_Day_Hrs  \\\n",
       "58                       (1.32)                            6.9   \n",
       "59                       (0.41)                            6.9   \n",
       "60                       (1.65)                            6.9   \n",
       "63                          NaN                            NaN   \n",
       "64                          NaN                            NaN   \n",
       "\n",
       "   Standard_Error_Elementary_Hrs/Day Secondary_ADA_Percentage  \\\n",
       "58                            (0.09)                     92.8   \n",
       "59                            (0.05)                     93.0   \n",
       "60                            (0.05)                     92.4   \n",
       "63                               NaN                      NaN   \n",
       "64                               NaN                      NaN   \n",
       "\n",
       "   Secondary_Standard_Error_ADA Secondary_Avg_School_Day_Hrs  \\\n",
       "58                       (0.41)                          6.8   \n",
       "59                       (1.91)                          7.0   \n",
       "60                       (0.75)                          7.0   \n",
       "63                          NaN                          NaN   \n",
       "64                          NaN                          NaN   \n",
       "\n",
       "   Standard_Error_Secondary_Hrs/Day  \n",
       "58                           (0.14)  \n",
       "59                           (0.14)  \n",
       "60                           (0.07)  \n",
       "63                              NaN  \n",
       "64                              NaN  "
      ]
     },
     "execution_count": 1318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Printing tail to make sure that all the rows I wanted to drop have been dropped. \n",
    "dfa.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 54 entries, 0 to 64\n",
      "Data columns (total 17 columns):\n",
      "State                                54 non-null object\n",
      "Total_ADA_Percentage                 52 non-null float64\n",
      "Total_Standard_Error_ADA             52 non-null object\n",
      "Total_Avg_School_Day_Hrs             52 non-null float64\n",
      "Standard_Error_Total_Hrs/Day         52 non-null object\n",
      "Total_Avg_School_Days_Year           52 non-null float64\n",
      "Standard_Error_Total_Days/Year       52 non-null object\n",
      "Total_Avg_School_Total_Hrs/Year      52 non-null object\n",
      "Standard_Error_Total_Hrs/Year        52 non-null object\n",
      "Elementary_ADA_Percentage            52 non-null float64\n",
      "Elementary_Standard_Error_AD         52 non-null object\n",
      "Elementary_Avg_School_Day_Hrs        52 non-null float64\n",
      "Standard_Error_Elementary_Hrs/Day    52 non-null object\n",
      "Secondary_ADA_Percentage             52 non-null object\n",
      "Secondary_Standard_Error_ADA         52 non-null object\n",
      "Secondary_Avg_School_Day_Hrs         52 non-null object\n",
      "Standard_Error_Secondary_Hrs/Day     52 non-null object\n",
      "dtypes: float64(5), object(12)\n",
      "memory usage: 7.6+ KB\n"
     ]
    }
   ],
   "source": [
    "#Here, I am using info to check if I am done. Here, I can see that all columns have been adaquetely named, and, they\n",
    "#all have the same number of entries in each column (excluding state because of the 2 remaining notes). This is a \n",
    "#huge contrast to the initial time I ran info so now, I think this means that I am done. \n",
    "\n",
    "dfa.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This lab was very tedious and took me a lot of time. Lik eprobably around 5+ hours since there was so much tedios work to be done. The most messy dataset I worked on was easily the Boing Boing Candy set. The attendance set was surprisingly fine and, I was able to clean up most, if not all of it. I though my methods of cleaning the columns and getting rid of NaN rows was very effective and I think I did a good job with that one. \n",
    "\n",
    "The Boing Boing set however, was a lot more work. I worked in the country and age columns and, I used replace() and contains() primarily throughout that dataset. My work was effective in that I did end up being able to clean it up however, the work was long and repetitive and I'm not 100% sure if my methods were the fastest way to get the job done. I am sure there are better and faster ways to work on those specific columns. \n",
    "\n",
    "In all, data cleaning was hard and this is probably the hardest lab we have done so far. I am very excited to move on from data cleaning because this was not as interesting as the other labs since the work was very repetitive and some of these data frames had a LOT of columns to work with. I am just glad I am not cleaning the whole Boing Boing Candy set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acknowlegements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* I would like to thank Ms. Sconyers for posting the \"Data Cleaning 101\" jupyter notebook because that was very helpful throughout this lab and was where I got a lot of my code from. Class is also very helpful for figuring out what to do with the data.\n",
    "\n",
    "\n",
    "* I would like to thank these sites for helping me find code:\n",
    "    dropping columns:    https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop.html\n",
    "    \n",
    "    ignoring na vals in .contains(): https://stackoverflow.com/questions/51068498/valueerror-cannot-index-with-vector-containing-na-nan-values/51969304\n",
    "    \n",
    "    replacing strings with sub-strings: https://stackoverflow.com/questions/39768547/replace-whole-string-if-it-contains-substring-in-pandas\n",
    "    \n",
    "    help with .contains(): https://stackoverflow.com/questions/39768547/replace-whole-string-if-it-contains-substring-in-pandas\n",
    "    \n",
    "* I would also like to thank myself for not giving up even though this took me like 6 hours. \n",
    "\n",
    "* I would also like to thank Theo for putting me in his acknowlegements every time. \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
